{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MACCROBAT_DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Annotation files are in brat standoff format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "General annotation structure\n",
    "All annotations follow the same basic structure: Each line contains one annotation, and each annotation is given an ID that appears first on the line, separated from the rest of the annotation by a single TAB character. The rest of the structure varies by annotation type.\n",
    "\n",
    "Examples of annotation for an entity (T1), an event trigger (T2), an event (E1) and a relation (R1) are shown in the following."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Annotation ID conventions\n",
    "All annotations IDs consist of a single upper-case character identifying the annotation type and a number. The initial ID characters relate to annotation types as follows:\n",
    "\n",
    "T: text-bound annotation\n",
    "R: relation\n",
    "E: event\n",
    "A: attribute\n",
    "M: modification (alias for attribute, for backward compatibility)\n",
    "N: normalization [new in v1.3]\n",
    "#: note"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1942171526.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Annotation ID conventions\u001B[0m\n\u001B[0m               ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "MACCROBAT_data_dir = \"./data/MACCROBAT\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['19860925',\n '26361640',\n '26228535',\n '27773410',\n '23678274',\n '25853982',\n '28103924',\n '27064109',\n '28154700',\n '20146086',\n '26656340',\n '28353558',\n '22515939',\n '28353588',\n '26309459',\n '28272235',\n '23242090',\n '23312850',\n '23124805',\n '26106249',\n '26313770',\n '26285706',\n '18416479',\n '28353613',\n '28151916',\n '26175648',\n '23468586',\n '28216610',\n '27059701',\n '28121940',\n '23077697',\n '27741115',\n '21067996',\n '28100235',\n '28151860',\n '25884600',\n '27904130',\n '19214295',\n '18787726',\n '22719160',\n '28422883',\n '26675562',\n '21477357',\n '25139918',\n '28353561',\n '22791498',\n '28538413',\n '26457578',\n '27842605',\n '20671919',\n '25155594',\n '26469535',\n '28353604',\n '28403092',\n '28239141',\n '28202869',\n '25024632',\n '28403086',\n '18666334',\n '25572898',\n '28296775',\n '22514576',\n '26584481',\n '28296749',\n '16778410',\n '19860007',\n '28190872',\n '25743872',\n '26523273',\n '28193213',\n '28120581',\n '26670309',\n '26336183',\n '25410883',\n '26530965',\n '28057913',\n '20977862',\n '25721834',\n '19860006',\n '19816630',\n '23155491',\n '28207542',\n '23864579',\n '26361431',\n '26264228',\n '28100279',\n '25370695',\n '26683938',\n '18258107',\n '22665582',\n '28248858',\n '27218632',\n '25023062',\n '25293719',\n '21308977',\n '22814979',\n '18561524',\n '26444414',\n '21923918',\n '23035161',\n '24898994',\n '28265107',\n '27974938',\n '24526194',\n '25858931',\n '28090049',\n '28115731',\n '17803823',\n '24294397',\n '27683825',\n '25661749',\n '28196820',\n '28248891',\n '18236639',\n '28033278',\n '21672201',\n '21254744',\n '28079821',\n '26216058',\n '24957905',\n '27196481',\n '26266396',\n '24518095',\n '26350418',\n '23897372',\n '15939911',\n '25926582',\n '27980261',\n '27980272',\n '25759562',\n '27821134',\n '23033875',\n '28173879',\n '18815636',\n '23076693',\n '21527041',\n '21505579',\n '24781756',\n '28250406',\n '26405496',\n '25934795',\n '26629302',\n '27661040',\n '25210224',\n '28202865',\n '28321070',\n '28403099',\n '28202862',\n '25295501',\n '28320420',\n '28595573',\n '26474553',\n '27130218',\n '28154669',\n '22218279',\n '28154281',\n '25246819',\n '28353556',\n '26664317',\n '26445413',\n '26257516',\n '28272214',\n '28154287',\n '19307547',\n '27990013',\n '27998312',\n '27906105',\n '24043987',\n '27842595',\n '28321071',\n '24654246',\n '21720478',\n '28383413',\n '19009665',\n '28767567',\n '19610147',\n '22781096',\n '28321073',\n '27100441',\n '26692730',\n '27793101',\n '27004009',\n '28151882',\n '28353569',\n '27057898',\n '26327988',\n '28353596',\n '27928148',\n '22520024',\n '27846860',\n '26395443',\n '21129213',\n '25793030',\n '27749582',\n '28559815',\n '24161539',\n '28250304',\n '28292056',\n '25410034',\n '26714786']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ids = []\n",
    "for file in os.listdir(MACCROBAT_data_dir):\n",
    "    file_id = file.split(\".\")[0]\n",
    "    if file_id not in file_ids:\n",
    "        file_ids.append(file_id)\n",
    "file_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "{'#', '*', 'A', 'E', 'R', 'T'}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = []\n",
    "for ann_file in [os.path.join(MACCROBAT_data_dir, file_id+\".ann\") for file_id in file_ids]:\n",
    "    with open(ann_file) as f:\n",
    "        for line in f.readlines():\n",
    "            tags.append(line.split(\"\\t\")[0][0])\n",
    "\n",
    "set(tags)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For named entity recognition, only the T tags are needed to generate the BIO format. The other tags such as #, *, A, E, and R are used for representing different types of information in the .ann files and are not directly related to named entity recognition.\n",
    "\n",
    "\\# is used to denote comments in the annotation file.\n",
    "\\* is used to represent coreference annotations.\n",
    "A is used to represent attribute annotations.\n",
    "E is used to represent event annotations.\n",
    "R is used to represent relation annotations.\n",
    "\n",
    "Therefore, we can ignore all other tags except for the T tags when generating the BIO format for named entity recognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find Entity types in ann files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "# create an empty list to store the DataFrames\n",
    "df_list = []\n",
    "\n",
    "for ann_file in [os.path.join(MACCROBAT_data_dir, file_id+\".ann\") for file_id in file_ids]:\n",
    "    # read the TSV file with consecutive tabs treated as a single delimiter\n",
    "    df = pd.read_csv(ann_file, sep=\"\\t+\", header=None, names=['id', 'entity_with_range', 'word'], engine='python')\n",
    "\n",
    "    # selecting only T tag rows\n",
    "    df = df[df.iloc[:,0].str.startswith('T')]\n",
    "\n",
    "    df['file_name'] = f\"{os.path.splitext(ann_file)[0]}.txt\"\n",
    "\n",
    "    df_list.append(df)\n",
    "\n",
    "ann_df = pd.concat(df_list)\n",
    "ann_df = ann_df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "   id     entity_with_range         word                      file_name\n0  T1              Age 4 15  24-year-old  ./data/MACCROBAT/19860925.txt\n1  T2             Sex 28 32         male  ./data/MACCROBAT/19860925.txt\n2  T3         History 16 27  non-smoking  ./data/MACCROBAT/19860925.txt\n3  T4  Clinical_event 41 50    presented  ./data/MACCROBAT/19860925.txt\n4  T5    Sign_symptom 65 75   hemoptysis  ./data/MACCROBAT/19860925.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>entity_with_range</th>\n      <th>word</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>T1</td>\n      <td>Age 4 15</td>\n      <td>24-year-old</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>T2</td>\n      <td>Sex 28 32</td>\n      <td>male</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T3</td>\n      <td>History 16 27</td>\n      <td>non-smoking</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T4</td>\n      <td>Clinical_event 41 50</td>\n      <td>presented</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T5</td>\n      <td>Sign_symptom 65 75</td>\n      <td>hemoptysis</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "(25041, 4)"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "         id                                  entity_with_range  \\\n39      T40                   Disease_disorder 701 714;730 735   \n1190    T31                         Dosage 4085 4093;4103 4108   \n1272   T160                         Dosage 3117 3124;3135 3141   \n1469   T101           Detailed_description 2552 2559;2585 2654   \n2376    T42                     Administration 704 715;721 726   \n2380    T47                             Dosage 828 835;861 879   \n2381    T48                             Dosage 849 857;861 879   \n2853    T18               Diagnostic_procedure 341 350;357 358   \n3335    T16                   Disease_disorder 315 317;319 330   \n3336    T15                   Disease_disorder 297 313;319 330   \n3348    T28               Diagnostic_procedure 606 621;641 647   \n3359    T39           Diagnostic_procedure 1017 1032;1052 1058   \n3377    T59           Diagnostic_procedure 1316 1318;1328 1336   \n3380    T62           Biological_structure 1386 1391;1408 1412   \n3405    T86                            History 606 621;641 647   \n4622   T121           Biological_structure 2001 2005;2034 2037   \n4625   T124           Diagnostic_procedure 2114 2133;2139 2143   \n4654   T154           Biological_structure 2428 2438;2444 2463   \n4655   T155           Biological_structure 2428 2438;2472 2499   \n5443    T28                          Lab_value 535 538;546 550   \n5623   T110                      Lab_value 2015 2024;2052 2061   \n9738    T59           Biological_structure 1644 1653;1673 1684   \n11557   T15                   Disease_disorder 474 481;490 503   \n11561   T19           Diagnostic_procedure 2831 2851;2858 2859   \n11576   T34           Diagnostic_procedure 2637 2653;2667 2674   \n11584   T42           Diagnostic_procedure 2296 2320;2327 2335   \n11588   T46           Diagnostic_procedure 2362 2371;2375 2377   \n11589   T47           Diagnostic_procedure 2362 2371;2383 2386   \n13564   T79           Detailed_description 1366 1373;1386 1404   \n13826   T89                      Lab_value 1596 1600;1628 1631   \n13830   T93                      Lab_value 1657 1661;1690 1693   \n13860  T123           Diagnostic_procedure 2306 2308;2316 2323   \n16564   T66                   Sign_symptom 1557 1559;1560 1567   \n16578   T80           Detailed_description 2186 2188;2189 2196   \n16585   T87           Diagnostic_procedure 2427 2429;2430 2437   \n17000   T87  Other_event 1746 1813;1814 1845;1846 1878;1879...   \n17808  T163                   Other_entity 4047 4155;4156 4238   \n17849   T39           Biological_structure 1101 1111;1121 1126   \n17850   T40           Biological_structure 1101 1111;1131 1137   \n17856   T46                      Lab_value 1439 1446;1457 1476   \n17879   T69           Biological_structure 2352 2357;2367 2371   \n17895   T85           Biological_structure 2873 2880;2902 2912   \n17896   T86           Biological_structure 2873 2880;2917 2926   \n17943  T133           Biological_structure 1645 1650;1660 1673   \n17948  T138               Disease_disorder 1246 1252;1261 1274   \n18823   T51                           Date 1251 1257;1274 1276   \n20497   T26                               Time 464 465;477 484   \n20499   T28                               Time 467 468;477 484   \n20555   T84           Biological_structure 1610 1633;1652 1658   \n20591  T120           Biological_structure 2533 2540;2559 2570   \n20592  T121           Biological_structure 2542 2547;2559 2570   \n21984   T98                          Shape 1739 1743;1761 1766   \n22069   T75                   Sign_symptom 1994 2004;2021 2029   \n22621   T35               Biological_structure 900 905;915 918   \n22623   T37                          Lab_value 926 929;938 939   \n\n                                                    word  \\\n39                                   granular cell tumor   \n1190                                      low dose daily   \n1272                                      1500 mg weekly   \n1469   neither had developed any signs or symptoms su...   \n2376                                   intravenous bolus   \n2380                          5 mg/kg every 4 to 6 weeks   \n2381                         10 mg/kg every 4 to 6 weeks   \n2853                                         Hepatitis C   \n3335                                      LV dysfunction   \n3336                        left ventricular dysfunction   \n3348                              total carnitine levels   \n3359                              total carnitine levels   \n3377                                         LV function   \n3380                                          basal wall   \n3405                              total carnitine levels   \n4622                                            left arm   \n4625                            computed tomography scan   \n4654                      origins of subclavian arteries   \n4655              origins of right common carotid artery   \n5443                                            386  U/L   \n5623                                 Frequency decreased   \n9738                               pericolic lymph nodes   \n11557                              cardiac malformations   \n11561                             DNA Polymerase Gamma 2   \n11576                           Citrate synthase content   \n11584                  electron transport chain activity   \n11588                                       complexes II   \n11589                                      complexes III   \n13564                         without rebound tenderness   \n13826                                           6/24 N36   \n13830                                           6/18 N36   \n13860                                         T1 signals   \n16564                                         H. cinaedi   \n16578                                         H. cinaedi   \n16585                                         H. cinaedi   \n17000  Atrial septal defect ostium secundum type with...   \n17808  and we recommended no further exposure to lead...   \n17849                                   mandibular ramus   \n17850                                  mandibular corpus   \n17856                        shorter than the other side   \n17879                                         right ears   \n17895                                 cochlea vestibulum   \n17896                                  cochlea utriculum   \n17943                                right hemimandibula   \n17948                               Number abnormalities   \n18823                                          age of 44   \n20497                                          1 minutes   \n20499                                          5 minutes   \n20555                     individual COX-positive fibers   \n20591                                stomach homogenates   \n20592                                  ileum homogenates   \n21984                                         edge clear   \n22069                                perineural invasion   \n22621                                          right eye   \n22623                                              561 μ   \n\n                           file_name  \n39     ./data/MACCROBAT/19860925.txt  \n1190   ./data/MACCROBAT/20146086.txt  \n1272   ./data/MACCROBAT/20146086.txt  \n1469   ./data/MACCROBAT/28353558.txt  \n2376   ./data/MACCROBAT/23124805.txt  \n2380   ./data/MACCROBAT/23124805.txt  \n2381   ./data/MACCROBAT/23124805.txt  \n2853   ./data/MACCROBAT/18416479.txt  \n3335   ./data/MACCROBAT/23468586.txt  \n3336   ./data/MACCROBAT/23468586.txt  \n3348   ./data/MACCROBAT/23468586.txt  \n3359   ./data/MACCROBAT/23468586.txt  \n3377   ./data/MACCROBAT/23468586.txt  \n3380   ./data/MACCROBAT/23468586.txt  \n3405   ./data/MACCROBAT/23468586.txt  \n4622   ./data/MACCROBAT/19214295.txt  \n4625   ./data/MACCROBAT/19214295.txt  \n4654   ./data/MACCROBAT/19214295.txt  \n4655   ./data/MACCROBAT/19214295.txt  \n5443   ./data/MACCROBAT/28353561.txt  \n5623   ./data/MACCROBAT/22791498.txt  \n9738   ./data/MACCROBAT/19816630.txt  \n11557  ./data/MACCROBAT/21308977.txt  \n11561  ./data/MACCROBAT/21308977.txt  \n11576  ./data/MACCROBAT/21308977.txt  \n11584  ./data/MACCROBAT/21308977.txt  \n11588  ./data/MACCROBAT/21308977.txt  \n11589  ./data/MACCROBAT/21308977.txt  \n13564  ./data/MACCROBAT/17803823.txt  \n13826  ./data/MACCROBAT/25661749.txt  \n13830  ./data/MACCROBAT/25661749.txt  \n13860  ./data/MACCROBAT/25661749.txt  \n16564  ./data/MACCROBAT/28173879.txt  \n16578  ./data/MACCROBAT/28173879.txt  \n16585  ./data/MACCROBAT/28173879.txt  \n17000  ./data/MACCROBAT/21505579.txt  \n17808  ./data/MACCROBAT/27661040.txt  \n17849  ./data/MACCROBAT/25210224.txt  \n17850  ./data/MACCROBAT/25210224.txt  \n17856  ./data/MACCROBAT/25210224.txt  \n17879  ./data/MACCROBAT/25210224.txt  \n17895  ./data/MACCROBAT/25210224.txt  \n17896  ./data/MACCROBAT/25210224.txt  \n17943  ./data/MACCROBAT/25210224.txt  \n17948  ./data/MACCROBAT/25210224.txt  \n18823  ./data/MACCROBAT/28595573.txt  \n20497  ./data/MACCROBAT/19307547.txt  \n20499  ./data/MACCROBAT/19307547.txt  \n20555  ./data/MACCROBAT/19307547.txt  \n20591  ./data/MACCROBAT/19307547.txt  \n20592  ./data/MACCROBAT/19307547.txt  \n21984  ./data/MACCROBAT/28767567.txt  \n22069  ./data/MACCROBAT/19610147.txt  \n22621  ./data/MACCROBAT/26692730.txt  \n22623  ./data/MACCROBAT/26692730.txt  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>entity_with_range</th>\n      <th>word</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>T40</td>\n      <td>Disease_disorder 701 714;730 735</td>\n      <td>granular cell tumor</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>1190</th>\n      <td>T31</td>\n      <td>Dosage 4085 4093;4103 4108</td>\n      <td>low dose daily</td>\n      <td>./data/MACCROBAT/20146086.txt</td>\n    </tr>\n    <tr>\n      <th>1272</th>\n      <td>T160</td>\n      <td>Dosage 3117 3124;3135 3141</td>\n      <td>1500 mg weekly</td>\n      <td>./data/MACCROBAT/20146086.txt</td>\n    </tr>\n    <tr>\n      <th>1469</th>\n      <td>T101</td>\n      <td>Detailed_description 2552 2559;2585 2654</td>\n      <td>neither had developed any signs or symptoms su...</td>\n      <td>./data/MACCROBAT/28353558.txt</td>\n    </tr>\n    <tr>\n      <th>2376</th>\n      <td>T42</td>\n      <td>Administration 704 715;721 726</td>\n      <td>intravenous bolus</td>\n      <td>./data/MACCROBAT/23124805.txt</td>\n    </tr>\n    <tr>\n      <th>2380</th>\n      <td>T47</td>\n      <td>Dosage 828 835;861 879</td>\n      <td>5 mg/kg every 4 to 6 weeks</td>\n      <td>./data/MACCROBAT/23124805.txt</td>\n    </tr>\n    <tr>\n      <th>2381</th>\n      <td>T48</td>\n      <td>Dosage 849 857;861 879</td>\n      <td>10 mg/kg every 4 to 6 weeks</td>\n      <td>./data/MACCROBAT/23124805.txt</td>\n    </tr>\n    <tr>\n      <th>2853</th>\n      <td>T18</td>\n      <td>Diagnostic_procedure 341 350;357 358</td>\n      <td>Hepatitis C</td>\n      <td>./data/MACCROBAT/18416479.txt</td>\n    </tr>\n    <tr>\n      <th>3335</th>\n      <td>T16</td>\n      <td>Disease_disorder 315 317;319 330</td>\n      <td>LV dysfunction</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>3336</th>\n      <td>T15</td>\n      <td>Disease_disorder 297 313;319 330</td>\n      <td>left ventricular dysfunction</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>3348</th>\n      <td>T28</td>\n      <td>Diagnostic_procedure 606 621;641 647</td>\n      <td>total carnitine levels</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>3359</th>\n      <td>T39</td>\n      <td>Diagnostic_procedure 1017 1032;1052 1058</td>\n      <td>total carnitine levels</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>3377</th>\n      <td>T59</td>\n      <td>Diagnostic_procedure 1316 1318;1328 1336</td>\n      <td>LV function</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>3380</th>\n      <td>T62</td>\n      <td>Biological_structure 1386 1391;1408 1412</td>\n      <td>basal wall</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>3405</th>\n      <td>T86</td>\n      <td>History 606 621;641 647</td>\n      <td>total carnitine levels</td>\n      <td>./data/MACCROBAT/23468586.txt</td>\n    </tr>\n    <tr>\n      <th>4622</th>\n      <td>T121</td>\n      <td>Biological_structure 2001 2005;2034 2037</td>\n      <td>left arm</td>\n      <td>./data/MACCROBAT/19214295.txt</td>\n    </tr>\n    <tr>\n      <th>4625</th>\n      <td>T124</td>\n      <td>Diagnostic_procedure 2114 2133;2139 2143</td>\n      <td>computed tomography scan</td>\n      <td>./data/MACCROBAT/19214295.txt</td>\n    </tr>\n    <tr>\n      <th>4654</th>\n      <td>T154</td>\n      <td>Biological_structure 2428 2438;2444 2463</td>\n      <td>origins of subclavian arteries</td>\n      <td>./data/MACCROBAT/19214295.txt</td>\n    </tr>\n    <tr>\n      <th>4655</th>\n      <td>T155</td>\n      <td>Biological_structure 2428 2438;2472 2499</td>\n      <td>origins of right common carotid artery</td>\n      <td>./data/MACCROBAT/19214295.txt</td>\n    </tr>\n    <tr>\n      <th>5443</th>\n      <td>T28</td>\n      <td>Lab_value 535 538;546 550</td>\n      <td>386  U/L</td>\n      <td>./data/MACCROBAT/28353561.txt</td>\n    </tr>\n    <tr>\n      <th>5623</th>\n      <td>T110</td>\n      <td>Lab_value 2015 2024;2052 2061</td>\n      <td>Frequency decreased</td>\n      <td>./data/MACCROBAT/22791498.txt</td>\n    </tr>\n    <tr>\n      <th>9738</th>\n      <td>T59</td>\n      <td>Biological_structure 1644 1653;1673 1684</td>\n      <td>pericolic lymph nodes</td>\n      <td>./data/MACCROBAT/19816630.txt</td>\n    </tr>\n    <tr>\n      <th>11557</th>\n      <td>T15</td>\n      <td>Disease_disorder 474 481;490 503</td>\n      <td>cardiac malformations</td>\n      <td>./data/MACCROBAT/21308977.txt</td>\n    </tr>\n    <tr>\n      <th>11561</th>\n      <td>T19</td>\n      <td>Diagnostic_procedure 2831 2851;2858 2859</td>\n      <td>DNA Polymerase Gamma 2</td>\n      <td>./data/MACCROBAT/21308977.txt</td>\n    </tr>\n    <tr>\n      <th>11576</th>\n      <td>T34</td>\n      <td>Diagnostic_procedure 2637 2653;2667 2674</td>\n      <td>Citrate synthase content</td>\n      <td>./data/MACCROBAT/21308977.txt</td>\n    </tr>\n    <tr>\n      <th>11584</th>\n      <td>T42</td>\n      <td>Diagnostic_procedure 2296 2320;2327 2335</td>\n      <td>electron transport chain activity</td>\n      <td>./data/MACCROBAT/21308977.txt</td>\n    </tr>\n    <tr>\n      <th>11588</th>\n      <td>T46</td>\n      <td>Diagnostic_procedure 2362 2371;2375 2377</td>\n      <td>complexes II</td>\n      <td>./data/MACCROBAT/21308977.txt</td>\n    </tr>\n    <tr>\n      <th>11589</th>\n      <td>T47</td>\n      <td>Diagnostic_procedure 2362 2371;2383 2386</td>\n      <td>complexes III</td>\n      <td>./data/MACCROBAT/21308977.txt</td>\n    </tr>\n    <tr>\n      <th>13564</th>\n      <td>T79</td>\n      <td>Detailed_description 1366 1373;1386 1404</td>\n      <td>without rebound tenderness</td>\n      <td>./data/MACCROBAT/17803823.txt</td>\n    </tr>\n    <tr>\n      <th>13826</th>\n      <td>T89</td>\n      <td>Lab_value 1596 1600;1628 1631</td>\n      <td>6/24 N36</td>\n      <td>./data/MACCROBAT/25661749.txt</td>\n    </tr>\n    <tr>\n      <th>13830</th>\n      <td>T93</td>\n      <td>Lab_value 1657 1661;1690 1693</td>\n      <td>6/18 N36</td>\n      <td>./data/MACCROBAT/25661749.txt</td>\n    </tr>\n    <tr>\n      <th>13860</th>\n      <td>T123</td>\n      <td>Diagnostic_procedure 2306 2308;2316 2323</td>\n      <td>T1 signals</td>\n      <td>./data/MACCROBAT/25661749.txt</td>\n    </tr>\n    <tr>\n      <th>16564</th>\n      <td>T66</td>\n      <td>Sign_symptom 1557 1559;1560 1567</td>\n      <td>H. cinaedi</td>\n      <td>./data/MACCROBAT/28173879.txt</td>\n    </tr>\n    <tr>\n      <th>16578</th>\n      <td>T80</td>\n      <td>Detailed_description 2186 2188;2189 2196</td>\n      <td>H. cinaedi</td>\n      <td>./data/MACCROBAT/28173879.txt</td>\n    </tr>\n    <tr>\n      <th>16585</th>\n      <td>T87</td>\n      <td>Diagnostic_procedure 2427 2429;2430 2437</td>\n      <td>H. cinaedi</td>\n      <td>./data/MACCROBAT/28173879.txt</td>\n    </tr>\n    <tr>\n      <th>17000</th>\n      <td>T87</td>\n      <td>Other_event 1746 1813;1814 1845;1846 1878;1879...</td>\n      <td>Atrial septal defect ostium secundum type with...</td>\n      <td>./data/MACCROBAT/21505579.txt</td>\n    </tr>\n    <tr>\n      <th>17808</th>\n      <td>T163</td>\n      <td>Other_entity 4047 4155;4156 4238</td>\n      <td>and we recommended no further exposure to lead...</td>\n      <td>./data/MACCROBAT/27661040.txt</td>\n    </tr>\n    <tr>\n      <th>17849</th>\n      <td>T39</td>\n      <td>Biological_structure 1101 1111;1121 1126</td>\n      <td>mandibular ramus</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17850</th>\n      <td>T40</td>\n      <td>Biological_structure 1101 1111;1131 1137</td>\n      <td>mandibular corpus</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17856</th>\n      <td>T46</td>\n      <td>Lab_value 1439 1446;1457 1476</td>\n      <td>shorter than the other side</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17879</th>\n      <td>T69</td>\n      <td>Biological_structure 2352 2357;2367 2371</td>\n      <td>right ears</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17895</th>\n      <td>T85</td>\n      <td>Biological_structure 2873 2880;2902 2912</td>\n      <td>cochlea vestibulum</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17896</th>\n      <td>T86</td>\n      <td>Biological_structure 2873 2880;2917 2926</td>\n      <td>cochlea utriculum</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17943</th>\n      <td>T133</td>\n      <td>Biological_structure 1645 1650;1660 1673</td>\n      <td>right hemimandibula</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>17948</th>\n      <td>T138</td>\n      <td>Disease_disorder 1246 1252;1261 1274</td>\n      <td>Number abnormalities</td>\n      <td>./data/MACCROBAT/25210224.txt</td>\n    </tr>\n    <tr>\n      <th>18823</th>\n      <td>T51</td>\n      <td>Date 1251 1257;1274 1276</td>\n      <td>age of 44</td>\n      <td>./data/MACCROBAT/28595573.txt</td>\n    </tr>\n    <tr>\n      <th>20497</th>\n      <td>T26</td>\n      <td>Time 464 465;477 484</td>\n      <td>1 minutes</td>\n      <td>./data/MACCROBAT/19307547.txt</td>\n    </tr>\n    <tr>\n      <th>20499</th>\n      <td>T28</td>\n      <td>Time 467 468;477 484</td>\n      <td>5 minutes</td>\n      <td>./data/MACCROBAT/19307547.txt</td>\n    </tr>\n    <tr>\n      <th>20555</th>\n      <td>T84</td>\n      <td>Biological_structure 1610 1633;1652 1658</td>\n      <td>individual COX-positive fibers</td>\n      <td>./data/MACCROBAT/19307547.txt</td>\n    </tr>\n    <tr>\n      <th>20591</th>\n      <td>T120</td>\n      <td>Biological_structure 2533 2540;2559 2570</td>\n      <td>stomach homogenates</td>\n      <td>./data/MACCROBAT/19307547.txt</td>\n    </tr>\n    <tr>\n      <th>20592</th>\n      <td>T121</td>\n      <td>Biological_structure 2542 2547;2559 2570</td>\n      <td>ileum homogenates</td>\n      <td>./data/MACCROBAT/19307547.txt</td>\n    </tr>\n    <tr>\n      <th>21984</th>\n      <td>T98</td>\n      <td>Shape 1739 1743;1761 1766</td>\n      <td>edge clear</td>\n      <td>./data/MACCROBAT/28767567.txt</td>\n    </tr>\n    <tr>\n      <th>22069</th>\n      <td>T75</td>\n      <td>Sign_symptom 1994 2004;2021 2029</td>\n      <td>perineural invasion</td>\n      <td>./data/MACCROBAT/19610147.txt</td>\n    </tr>\n    <tr>\n      <th>22621</th>\n      <td>T35</td>\n      <td>Biological_structure 900 905;915 918</td>\n      <td>right eye</td>\n      <td>./data/MACCROBAT/26692730.txt</td>\n    </tr>\n    <tr>\n      <th>22623</th>\n      <td>T37</td>\n      <td>Lab_value 926 929;938 939</td>\n      <td>561 μ</td>\n      <td>./data/MACCROBAT/26692730.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df[ann_df['entity_with_range'].str.split().str.len() > 3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above entries represents the tagged text spans more than one disjoint ranges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the \"B\" prefix is used to indicate the beginning of an entity, while the \"I\" prefix is used to indicate an intermediate token within an entity. When there are disjoint ranges for an entity, we can start a new entity with a \"B\" prefix for each range.\n",
    "\n",
    "Including the full text that spans disjoint ranges in the BIO format will help the model learn to recognize the entire entity, even if it is fragmented across multiple parts of the text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "   id          entity     range         word                      file_name\n0  T1             Age   [4, 15]  24-year-old  ./data/MACCROBAT/19860925.txt\n1  T2             Sex  [28, 32]         male  ./data/MACCROBAT/19860925.txt\n2  T3         History  [16, 27]  non-smoking  ./data/MACCROBAT/19860925.txt\n3  T4  Clinical_event  [41, 50]    presented  ./data/MACCROBAT/19860925.txt\n4  T5    Sign_symptom  [65, 75]   hemoptysis  ./data/MACCROBAT/19860925.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>entity</th>\n      <th>range</th>\n      <th>word</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>T1</td>\n      <td>Age</td>\n      <td>[4, 15]</td>\n      <td>24-year-old</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>T2</td>\n      <td>Sex</td>\n      <td>[28, 32]</td>\n      <td>male</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T3</td>\n      <td>History</td>\n      <td>[16, 27]</td>\n      <td>non-smoking</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T4</td>\n      <td>Clinical_event</td>\n      <td>[41, 50]</td>\n      <td>presented</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T5</td>\n      <td>Sign_symptom</td>\n      <td>[65, 75]</td>\n      <td>hemoptysis</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df['entity'] = ann_df['entity_with_range'].str.split().str[0]\n",
    "ann_df['range'] = ann_df['entity_with_range'].str.split().str[1:]\n",
    "ann_df = ann_df[['id', 'entity', 'range', 'word', 'file_name']]\n",
    "ann_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set of entities available in the dataset is as follows: \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Activity',\n 'Administration',\n 'Age',\n 'Area',\n 'Biological_attribute',\n 'Biological_structure',\n 'Clinical_event',\n 'Color',\n 'Coreference',\n 'Date',\n 'Detailed_description',\n 'Diagnostic_procedure',\n 'Disease_disorder',\n 'Distance',\n 'Dosage',\n 'Duration',\n 'Family_history',\n 'Frequency',\n 'Height',\n 'History',\n 'Lab_value',\n 'Mass',\n 'Medication',\n 'Nonbiological_location',\n 'Occupation',\n 'Other_entity',\n 'Other_event',\n 'Outcome',\n 'Personal_background',\n 'Qualitative_concept',\n 'Quantitative_concept',\n 'Severity',\n 'Sex',\n 'Shape',\n 'Sign_symptom',\n 'Subject',\n 'Texture',\n 'Therapeutic_procedure',\n 'Time',\n 'Volume',\n 'Weight'}"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The set of entities available in the dataset is as follows: \")\n",
    "set(ann_df['entity'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring each entities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "data": {
      "text/plain": "entity\nDiagnostic_procedure      4567\nSign_symptom              3359\nBiological_structure      2931\nDetailed_description      2901\nLab_value                 2858\nDisease_disorder          1362\nMedication                1076\nTherapeutic_procedure     1005\nDate                       731\nClinical_event             626\nHistory                    392\nSeverity                   369\nDosage                     362\nNonbiological_location     354\nCoreference                313\nDuration                   280\nAge                        206\nSex                        191\nAdministration             175\nDistance                   122\nActivity                   108\nFamily_history              81\nFrequency                   76\nShape                       65\nTime                        57\nPersonal_background         57\nSubject                     54\nColor                       52\nTexture                     46\nArea                        43\nOutcome                     42\nQualitative_concept         41\nVolume                      33\nQuantitative_concept        31\nOther_event                 22\nOther_entity                20\nOccupation                  13\nBiological_attribute        10\nWeight                       4\nHeight                       4\nMass                         2\ndtype: int64"
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df.groupby(['entity']).size().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "entity               \nActivity        16278               flexed\n                7071     physical exercise\nAdministration  16777                 oral\n                11207              topical\nAge             19252          23-year-old\n                               ...        \nTime            6758        first 24 hours\nVolume          18706        11 × 8 × 2 cm\n                24524                 5 mL\nWeight          24555               3132 g\n                5538                 83 kg\nName: word, Length: 82, dtype: object"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to select random rows from each group\n",
    "def select_random_rows(group):\n",
    "    return group.sample(n=min(2, len(group)), replace=False)\n",
    "\n",
    "# Apply the function to the DataFrame grouped by 'group'\n",
    "random_rows = ann_df.groupby('entity').apply(select_random_rows)\n",
    "\n",
    "# Print the selected random rows\n",
    "random_rows['word']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "selected_entities = ['Age', 'Biological_attribute', 'Biological_structure', 'Clinical_event', 'Diagnostic_procedure', 'Disease_disorder', 'Dosage', 'Family_history', 'Height', 'History', 'Lab_value', 'Mass', 'Medication', 'Sex', 'Sign_symptom', 'Therapeutic_procedure', 'Weight']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "   id          entity     range         word                      file_name\n0  T1             Age   [4, 15]  24-year-old  ./data/MACCROBAT/19860925.txt\n1  T2             Sex  [28, 32]         male  ./data/MACCROBAT/19860925.txt\n2  T3         History  [16, 27]  non-smoking  ./data/MACCROBAT/19860925.txt\n3  T4  Clinical_event  [41, 50]    presented  ./data/MACCROBAT/19860925.txt\n4  T5    Sign_symptom  [65, 75]   hemoptysis  ./data/MACCROBAT/19860925.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>entity</th>\n      <th>range</th>\n      <th>word</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>T1</td>\n      <td>Age</td>\n      <td>[4, 15]</td>\n      <td>24-year-old</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>T2</td>\n      <td>Sex</td>\n      <td>[28, 32]</td>\n      <td>male</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T3</td>\n      <td>History</td>\n      <td>[16, 27]</td>\n      <td>non-smoking</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T4</td>\n      <td>Clinical_event</td>\n      <td>[41, 50]</td>\n      <td>presented</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T5</td>\n      <td>Sign_symptom</td>\n      <td>[65, 75]</td>\n      <td>hemoptysis</td>\n      <td>./data/MACCROBAT/19860925.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ann_df = ann_df[ann_df['entity'].isin(selected_entities)]\n",
    "filtered_ann_df = filtered_ann_df.reset_index(drop=True)\n",
    "filtered_ann_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "(19036, 5)"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ann_df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating BIO format files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Function to read txt files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the txt file\n",
    "with open('./data/MACCROBAT/19860925.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Read the ann file\n",
    "with open('./data/MACCROBAT/19860925.ann', 'r') as f:\n",
    "    ann = f.readlines()\n",
    "\n",
    "# Define a function to convert the ann file into a list of (label, start, end) tuples\n",
    "def parse_ann(ann):\n",
    "    entities = []\n",
    "    for line in ann:\n",
    "        fields = line.strip().split('\\t')\n",
    "        if fields[0].startswith('T'):\n",
    "            entity_with_range, word = fields[1], fields[2]\n",
    "            label = entity_with_range.split()[0]\n",
    "            if label in selected_entities:\n",
    "                ranges = [\n",
    "                    (\n",
    "                        int(start_end.split()[0]),\n",
    "                        int(start_end.split()[1])\n",
    "                    )\n",
    "                    for start_end in ' '.join(entity_with_range.split()[1:]).split(';')\n",
    "                ]\n",
    "                for start, end in ranges:\n",
    "                    entities.append((label, start, end))\n",
    "    return entities\n",
    "\n",
    "# Convert the ann file into a list of (label, start, end) tuples\n",
    "entities = parse_ann(ann)\n",
    "\n",
    "# Define a function to convert the entities into a list of (token, tag) tuples in BIO format\n",
    "def entities_to_bio(text, entities):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "    tags = ['O'] * len(tokens)\n",
    "    for label, start, end in entities:\n",
    "        for i in range(len(tokens)):\n",
    "            token_start = text.find(tokens[i])\n",
    "            if start <= token_start < end:\n",
    "                if token_start == start:\n",
    "                    tags[i] = 'B-' + label\n",
    "                else:\n",
    "                    tags[i] = 'I-' + label\n",
    "    return list(zip(tokens, tags))\n",
    "\n",
    "\n",
    "\n",
    "# Convert the entities into a list of (token, tag) tuples in BIO format\n",
    "bio = entities_to_bio(text, entities)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our O\n",
      "24 B-Age\n",
      "year I-Age\n",
      "old I-Age\n",
      "non B-History\n",
      "smoking I-History\n",
      "male B-Sex\n",
      "patient O\n",
      "presented B-Clinical_event\n",
      "with O\n",
      "repeated O\n",
      "hemoptysis B-Sign_symptom\n",
      "in I-History\n",
      "May O\n",
      "2008 O\n",
      "with O\n",
      "4 I-Age\n",
      "days O\n",
      "of O\n",
      "concomitant O\n",
      "right B-Biological_structure\n",
      "thoracic I-Biological_structure\n",
      "pain B-Sign_symptom\n",
      "which O\n",
      "intensified O\n",
      "while O\n",
      "breathing O\n",
      "During O\n",
      "holidays B-History\n",
      "in I-History\n",
      "his I-History\n",
      "home I-History\n",
      "country I-History\n",
      "this O\n",
      "Cuban O\n",
      "patient O\n",
      "suffered O\n",
      "from O\n",
      "a I-Age\n",
      "cold B-Sign_symptom\n",
      "with O\n",
      "fever B-Sign_symptom\n",
      "and O\n",
      "a I-Age\n",
      "strong O\n",
      "cough B-Sign_symptom\n",
      "The O\n",
      "strong O\n",
      "dry O\n",
      "cough B-Sign_symptom\n",
      "persisted O\n",
      "after O\n",
      "recovery O\n",
      "from O\n",
      "the O\n",
      "cold B-Sign_symptom\n",
      "The O\n",
      "patient O\n",
      "did O\n",
      "not O\n",
      "report O\n",
      "any O\n",
      "loss B-Sign_symptom\n",
      "of O\n",
      "weight I-Sign_symptom\n",
      "The O\n",
      "initial O\n",
      "CT B-Diagnostic_procedure\n",
      "scan I-Diagnostic_procedure\n",
      "of O\n",
      "the O\n",
      "thorax B-Biological_structure\n",
      "showed O\n",
      "a I-Age\n",
      "12 O\n",
      "4 I-Age\n",
      "cm O\n",
      "solid O\n",
      "mass B-Sign_symptom\n",
      "paravertebral B-Biological_structure\n",
      "right B-Biological_structure\n",
      "in I-History\n",
      "the O\n",
      "lower B-Biological_structure\n",
      "thorax B-Biological_structure\n",
      "without O\n",
      "any O\n",
      "signs O\n",
      "of O\n",
      "metastases B-Sign_symptom\n",
      "Figure O\n",
      "1 O\n",
      "The O\n",
      "bronchoscopy B-Diagnostic_procedure\n",
      "Figure O\n",
      "2 B-Age\n",
      "with O\n",
      "non B-History\n",
      "bleeding O\n",
      "biopsy B-Diagnostic_procedure\n",
      "revealed O\n",
      "a I-Age\n",
      "mass B-Sign_symptom\n",
      "of O\n",
      "the O\n",
      "lower B-Biological_structure\n",
      "right B-Biological_structure\n",
      "bronchus I-Biological_structure\n",
      "which O\n",
      "histologically B-Diagnostic_procedure\n",
      "and O\n",
      "immunohistologically B-Diagnostic_procedure\n",
      "provided O\n",
      "evidence O\n",
      "of O\n",
      "a I-Age\n",
      "granular B-Disease_disorder\n",
      "cell I-Disease_disorder\n",
      "or I-Biological_structure\n",
      "Abrikossoff B-Disease_disorder\n",
      "tumor I-Disease_disorder\n",
      "1 O\n",
      "The O\n",
      "bronchial B-Diagnostic_procedure\n",
      "lavage I-Diagnostic_procedure\n",
      "which O\n",
      "followed O\n",
      "was O\n",
      "negative B-Lab_value\n",
      "for O\n",
      "malignant B-Biological_structure\n",
      "cells I-Biological_structure\n",
      "The O\n",
      "patient O\n",
      "was O\n",
      "discharged B-Clinical_event\n",
      "and O\n",
      "surgical O\n",
      "intervention O\n",
      "was O\n",
      "planned O\n",
      "Four O\n",
      "days O\n",
      "after O\n",
      "discharge B-Clinical_event\n",
      "a I-Age\n",
      "spontaneous O\n",
      "hemothorax B-Sign_symptom\n",
      "developed O\n",
      "The O\n",
      "patient O\n",
      "needed O\n",
      "to I-Diagnostic_procedure\n",
      "be O\n",
      "readmitted B-Clinical_event\n",
      "and O\n",
      "the O\n",
      "hemothorax B-Sign_symptom\n",
      "was O\n",
      "drained B-Therapeutic_procedure\n",
      "No O\n",
      "malignant B-Biological_structure\n",
      "cells I-Biological_structure\n",
      "were O\n",
      "detected O\n",
      "in I-History\n",
      "the O\n",
      "cytological B-Diagnostic_procedure\n",
      "examination I-Diagnostic_procedure\n",
      "of O\n",
      "the O\n",
      "drained B-Therapeutic_procedure\n",
      "liquid I-Biological_structure\n",
      "After O\n",
      "an O\n",
      "uneventful O\n",
      "course O\n",
      "and O\n",
      "decreasing B-Lab_value\n",
      "of O\n",
      "the O\n",
      "hematoma B-Sign_symptom\n",
      "the O\n",
      "tumor I-Disease_disorder\n",
      "was O\n",
      "excised B-Therapeutic_procedure\n",
      "by O\n",
      "performing O\n",
      "a I-Age\n",
      "lower B-Biological_structure\n",
      "right B-Biological_structure\n",
      "lobectomy I-Therapeutic_procedure\n",
      "6 O\n",
      "months O\n",
      "after O\n",
      "the O\n",
      "initial O\n",
      "admission O\n",
      "The O\n",
      "final O\n",
      "histological B-Diagnostic_procedure\n",
      "examination I-Diagnostic_procedure\n",
      "confirmed O\n",
      "a I-Age\n",
      "peribronchial B-Biological_structure\n",
      "and O\n",
      "infiltrating O\n",
      "S100 B-Diagnostic_procedure\n",
      "positive B-Lab_value\n",
      "tumor I-Disease_disorder\n",
      "supporting O\n",
      "the O\n",
      "Schwann O\n",
      "cell I-Disease_disorder\n",
      "origin O\n",
      "theory O\n",
      "with O\n",
      "very O\n",
      "low B-Biological_structure\n",
      "growth B-Diagnostic_procedure\n",
      "rate I-Diagnostic_procedure\n",
      "of O\n",
      "2 B-Age\n",
      "and O\n",
      "a I-Age\n",
      "size B-Diagnostic_procedure\n",
      "of O\n",
      "15 O\n",
      "mm I-Diagnostic_procedure\n",
      "Figure O\n",
      "3 O\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "for word, tag in bio:\n",
    "    print(word, tag)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "data": {
      "text/plain": "'./data/MACCROBAT'"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MACCROBAT_data_dir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "# def convert_ann_to_bio(input_dir, output_dir):\n",
    "#     for file in os.listdir(input_dir):\n",
    "#         if file.endswith('.txt'):\n",
    "#             # Read the corresponding txt file\n",
    "#             with open(os.path.join(input_dir, file), 'r', encoding='utf-8') as f:\n",
    "#                 text = f.read()\n",
    "#             # Find the corresponding ann file\n",
    "#             ann_file = os.path.join(input_dir, file.replace('.txt', '.ann'))\n",
    "#\n",
    "#             # tokenization\n",
    "#             tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "#             # Initialize a list to hold the BIO-formatted tags\n",
    "#             bio_tags = ['O'] * len(tokens)\n",
    "#\n",
    "#             # Read the annotation file\n",
    "#             with open(ann_file, 'r', encoding='utf-8') as f:\n",
    "#                 for line in f:\n",
    "#                     fields = line.strip().split('\\t')\n",
    "#                     # Get the tag and its starting and ending positions\n",
    "#                     if fields[0].startswith('T'):\n",
    "#                         entity_with_range, word = fields[1], fields[2]\n",
    "#                         label = entity_with_range.split()[0]\n",
    "#                         if label in selected_entities:\n",
    "#                             ranges = [\n",
    "#                                 (\n",
    "#                                     int(start_end.split()[0]),\n",
    "#                                     int(start_end.split()[1])\n",
    "#                                 )\n",
    "#                                 for start_end in ' '.join(entity_with_range.split()[1:]).split(';')\n",
    "#                             ]\n",
    "#                             # Keep track of the current position in the text\n",
    "#                             current_pos = 0\n",
    "#                             for i in range(len(tokens)):\n",
    "#                                 # Calculate the starting position of the token\n",
    "#                                 token_start = text.find(tokens[i], current_pos)\n",
    "#                                 token_end = token_start + len(tokens[i])\n",
    "#                                 # Update the current position in the text\n",
    "#                                 current_pos = token_end\n",
    "#                                 for start, end in ranges:\n",
    "#                                     if start <= token_start and end >= token_end:\n",
    "#                                         if token_start == start:\n",
    "#                                             bio_tags[i] = 'B-' + label\n",
    "#                                         else:\n",
    "#                                             bio_tags[i] = 'I-' + label\n",
    "#             # for token, tag in zip(tokens, bio_tags):\n",
    "#             #     print(token, tag)\n",
    "#\n",
    "#\n",
    "#             if not os.path.exists(output_dir):\n",
    "#                 os.makedirs(output_dir)\n",
    "#              # # Write the BIO tags to a new file\n",
    "#             with open(os.path.join(output_dir, file.replace('.txt', '.bio')), 'w', encoding='utf-8') as f:\n",
    "#                 for i in range(len(tokens)):\n",
    "#                     f.write(tokens[i] + '\\t' + bio_tags[i] + '\\n')\n",
    "#                 f.write('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "def convert_ann_to_bio(input_dir, output_dir):\n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.endswith('.txt'):\n",
    "            # Read the corresponding txt file\n",
    "            with open(os.path.join(input_dir, file), 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            # Find the corresponding ann file\n",
    "            ann_file = os.path.join(input_dir, file.replace('.txt', '.ann'))\n",
    "\n",
    "            # tokenization\n",
    "            sentences = text.split('\\n')\n",
    "            tokens = [word for sentence in sentences for word in sentence.split()]\n",
    "\n",
    "            # Initialize a list to hold the BIO-formatted tags\n",
    "            bio_tags = ['O'] * len(tokens)\n",
    "\n",
    "            # Read the annotation file\n",
    "            with open(ann_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    fields = line.strip().split('\\t')\n",
    "                    # Get the tag and its starting and ending positions\n",
    "                    if fields[0].startswith('T'):\n",
    "                        entity_with_range, word = fields[1], fields[2]\n",
    "                        label = entity_with_range.split()[0]\n",
    "                        if label in selected_entities:\n",
    "                            ranges = [\n",
    "                                (\n",
    "                                    int(start_end.split()[0]),\n",
    "                                    int(start_end.split()[1])\n",
    "                                )\n",
    "                                for start_end in ' '.join(entity_with_range.split()[1:]).split(';')\n",
    "                            ]\n",
    "                            # Keep track of the current position in the text\n",
    "                            current_pos = 0\n",
    "                            for i in range(len(tokens)):\n",
    "                                # Calculate the starting position of the token\n",
    "                                token_start = text.find(tokens[i], current_pos)\n",
    "                                token_end = token_start + len(tokens[i])\n",
    "                                # Update the current position in the text\n",
    "                                current_pos = token_end\n",
    "                                for start, end in ranges:\n",
    "                                    if start <= token_start and end >= token_end:\n",
    "                                        if token_start == start:\n",
    "                                            bio_tags[i] = 'B-' + label\n",
    "                                        else:\n",
    "                                            bio_tags[i] = 'I-' + label\n",
    "\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            # Write the BIO tags to a new file\n",
    "            with open(os.path.join(output_dir, file.replace('.txt', '.bio')), 'w', encoding='utf-8') as f:\n",
    "                sentence_start_index = 0\n",
    "                for sentence in sentences:\n",
    "                    sentence_tokens = sentence.split()\n",
    "                    sentence_length = len(sentence_tokens)\n",
    "                    sentence_end_index = sentence_start_index + sentence_length\n",
    "                    for i in range(sentence_start_index, sentence_end_index):\n",
    "                        f.write(sentence_tokens[i - sentence_start_index] + '\\t' + bio_tags[i] + '\\n')\n",
    "                    f.write('\\n')\n",
    "                    sentence_start_index = sentence_end_index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "def read_text_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def tokenize_text(text: str) -> List[str]:\n",
    "    return [word for sentence in text.split('\\n') for word in sentence.split()]\n",
    "\n",
    "def read_annotation_file(file_path: str, selected_entities: List[str]) -> List[Tuple[str, List[Tuple[int,int]]]]:\n",
    "    entity_ranges = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            # Get the tag and its starting and ending positions\n",
    "            if fields[0].startswith('T'):\n",
    "                entity_with_range, word = fields[1], fields[2]\n",
    "                label = entity_with_range.split()[0]\n",
    "                if label in selected_entities:\n",
    "                    ranges = [\n",
    "                        (\n",
    "                            int(start_end.split()[0]),\n",
    "                            int(start_end.split()[1])\n",
    "                        )\n",
    "                        for start_end in ' '.join(entity_with_range.split()[1:]).split(';')\n",
    "                    ]\n",
    "                    entity_ranges.append((label, ranges))\n",
    "    return entity_ranges\n",
    "\n",
    "def convert_ann_to_bio(input_dir: str, output_dir: str, selected_entities: List[str]):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            # Read the corresponding txt file\n",
    "            text = read_text_file(os.path.join(input_dir, file_name))\n",
    "\n",
    "            # Find the corresponding ann file\n",
    "            ann_file = os.path.join(input_dir, file_name.replace('.txt', '.ann'))\n",
    "\n",
    "            # tokenization\n",
    "            sentences = text.split('\\n')\n",
    "\n",
    "            # Tokenize the text\n",
    "            tokens = tokenize_text(text)\n",
    "\n",
    "            # Initialize a list to hold the BIO-formatted tags\n",
    "            bio_tags = ['O'] * len(tokens)\n",
    "\n",
    "            # Read the annotation file\n",
    "            entity_ranges = read_annotation_file(ann_file, selected_entities)\n",
    "\n",
    "            # Update the BIO tags\n",
    "            for label, ranges in entity_ranges:\n",
    "                # Keep track of the current position in the text\n",
    "                current_pos = 0\n",
    "                for i in range(len(tokens)):\n",
    "                    # Calculate the starting position of the token\n",
    "                    token_start = text.find(tokens[i], current_pos)\n",
    "                    token_end = token_start + len(tokens[i])\n",
    "                    # Update the current position in the text\n",
    "                    current_pos = token_end\n",
    "                    for start, end in ranges:\n",
    "                        if start <= token_start and end >= token_end:\n",
    "                            if token_start == start:\n",
    "                                bio_tags[i] = 'B-' + label\n",
    "                            else:\n",
    "                                bio_tags[i] = 'I-' + label\n",
    "\n",
    "\n",
    "\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            # Write the BIO tags to a new file\n",
    "            with open(os.path.join(output_dir, file.replace('.txt', '.bio')), 'w', encoding='utf-8') as f:\n",
    "                sentence_start_index = 0\n",
    "                for sentence in sentences:\n",
    "                    sentence_tokens = sentence.split()\n",
    "                    sentence_length = len(sentence_tokens)\n",
    "                    sentence_end_index = sentence_start_index + sentence_length\n",
    "                    for i in range(sentence_start_index, sentence_end_index):\n",
    "                        f.write(sentence_tokens[i - sentence_start_index] + '\\t' + bio_tags[i] + '\\n')\n",
    "                    f.write('\\n')\n",
    "                    sentence_start_index = sentence_end_index\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def read_text_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def tokenize_text(text: str) -> List[str]:\n",
    "    # Tokenize the text into a list of words\n",
    "    tokens = []\n",
    "    for sentence in text.split('\\n'):\n",
    "        for word in sentence.split():\n",
    "            # Remove trailing punctuation marks from the word\n",
    "            while word and word[-1] in string.punctuation:\n",
    "                word = word[:-1]\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    # tokens = [word for sentence in text.split('\\n') for word in sentence.split()]\n",
    "    # return tokens\n",
    "\n",
    "def get_start_end_range_to_token_index(tokens: List[str], entity_ranges: List[Tuple[str, int, int]]) -> Dict[Tuple[int, int], List[int]]:\n",
    "    # Initialize a dictionary to map each (start, end) range to the corresponding token indices\n",
    "    start_end_range_to_token_index = {}\n",
    "    # Keep track of the current position in the text\n",
    "    current_pos = 0\n",
    "    # Iterate over each token in the tokens list\n",
    "    for i in range(len(tokens)):\n",
    "        # Calculate the starting position of the token\n",
    "        token_start = text.find(tokens[i], current_pos)\n",
    "        token_end = token_start + len(tokens[i])\n",
    "        # Update the current position in the text\n",
    "        current_pos = token_end\n",
    "        # Check if the current token is inside any of the entity ranges\n",
    "        for label, start, end in entity_ranges:\n",
    "            if start <= token_start and end >= token_end:\n",
    "                # If the (start, end) range is not already in the dictionary, add it with an empty list\n",
    "                if (start, end) not in start_end_range_to_token_index:\n",
    "                    start_end_range_to_token_index[(start, end)] = []\n",
    "                # Add the index of the token to the list corresponding to the (start, end) range in the dictionary\n",
    "                start_end_range_to_token_index[(start, end)].append(i)\n",
    "    return start_end_range_to_token_index\n",
    "\n",
    "\n",
    "def read_annotation_file(file_path: str, selected_entities: List[str]) -> List[Tuple[str, List[Tuple[int,int]]]]:\n",
    "    entity_ranges = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            # Get the tag and its starting and ending positions\n",
    "            if fields[0].startswith('T'):\n",
    "                entity_with_range, word = fields[1], fields[2]\n",
    "                label = entity_with_range.split()[0]\n",
    "                if label in selected_entities:\n",
    "                    ranges = [\n",
    "                        (\n",
    "                            int(start_end.split()[0]),\n",
    "                            int(start_end.split()[1])\n",
    "                        )\n",
    "                        for start_end in ' '.join(entity_with_range.split()[1:]).split(';')\n",
    "                    ]\n",
    "                    entity_ranges.append((label, ranges))\n",
    "    # Sort the entity ranges based on start and end\n",
    "    entity_ranges = sorted(entity_ranges, key=lambda x: (x[1][0][0], x[1][0][1]))\n",
    "    return entity_ranges\n",
    "\n",
    "def convert_ann_to_bio(input_dir: str, output_dir: str, selected_entities: List[str]):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            # Read the corresponding txt file\n",
    "            text = read_text_file(os.path.join(input_dir, file_name))\n",
    "\n",
    "            # Find the corresponding ann file\n",
    "            ann_file = os.path.join(input_dir, file_name.replace('.txt', '.ann'))\n",
    "\n",
    "            # Tokenize the text\n",
    "            tokens = tokenize_text(text)\n",
    "\n",
    "            # Initialize a list to hold the BIO-formatted tags\n",
    "            bio_tags = ['O'] * len(tokens)\n",
    "\n",
    "            # Read the annotation file\n",
    "            entity_ranges = read_annotation_file(ann_file, selected_entities)\n",
    "            entity_ranges = [(name, *tup) for name, tup_list in entity_ranges for tup in tup_list]\n",
    "\n",
    "            start_end_2_idx = get_start_end_range_to_token_index(tokens, entity_ranges)\n",
    "\n",
    "            # Update the BIO tags\n",
    "            for label, start, end in entity_ranges:\n",
    "                # Get the list of token indices corresponding to the (start, end) range\n",
    "                token_indices = start_end_2_idx.get((start, end), [])\n",
    "                # Assign the BIO tags to each token index in the range\n",
    "                for i in token_indices:\n",
    "                    if i == token_indices[0]:\n",
    "                        bio_tags[i] = 'B-' + label\n",
    "                    else:\n",
    "                        bio_tags[i] = 'I-' + label\n",
    "\n",
    "            # Write the BIO tags to a new file\n",
    "            with open(os.path.join(output_dir, file_name.replace('.txt', '.bio')), 'w', encoding='utf-8') as f:\n",
    "                sentence_start_index = 0\n",
    "                for sentence in text.split('\\n'):\n",
    "                    sentence_tokens = sentence.split()\n",
    "                    sentence_length = len(sentence_tokens)\n",
    "                    sentence_end_index = sentence_start_index + sentence_length\n",
    "                    for i in range(sentence_start_index, sentence_end_index):\n",
    "                        f.write(sentence_tokens[i - sentence_start_index] + '\\t' + bio_tags[i] + '\\n')\n",
    "                    f.write('\\n')\n",
    "                    sentence_start_index = sentence_end_index\n",
    "\n",
    "    print(\"Conversion completed successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "convert_ann_to_bio('./data/MACCROBAT', './data/BIO_FILES', selected_entities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [],
   "source": [
    "with open('./data/MACCROBAT/28383413.txt', 'r') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "data": {
      "text/plain": "'leg.\\nAt the follow-up in late January 2016, the patient could not walk and live by herself and was depressed.\\nAt the latest follow-up'"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[4990:5123]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [],
   "source": [
    "# Read the corresponding txt file\n",
    "text = read_text_file('./data/MACCROBAT/28383413.txt')\n",
    "\n",
    "# Find the corresponding ann file\n",
    "ann_file = './data/MACCROBAT/28383413.ann'\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenize_text(text)\n",
    "\n",
    "# Initialize a list to hold the BIO-formatted tags\n",
    "bio_tags = ['O'] * len(tokens)\n",
    "\n",
    "# Read the annotation file\n",
    "entity_ranges = read_annotation_file(ann_file, selected_entities)\n",
    "entity_ranges = [(name, *tup) for name, tup_list in entity_ranges for tup in tup_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "outputs": [
    {
     "data": {
      "text/plain": "['n',\n 'March',\n '2015',\n 'a',\n '62-year-old',\n 'woman',\n 'was',\n 'admitted',\n 'to',\n 'our',\n 'hospital',\n 'She',\n 'complained',\n 'of',\n 'progressive',\n 'visual',\n 'disturbance',\n 'which',\n 'began',\n 'about',\n '4',\n 'years',\n 'ago',\n 'and',\n 'was',\n 'treated',\n 'as',\n 'cataract',\n 'in',\n 'local',\n 'hospital',\n 'but',\n 'no',\n 'relief',\n 'was',\n 'seen',\n 'On',\n 'the',\n 'contrary',\n 'the',\n 'symptoms',\n 'aggravated',\n 'half',\n 'a',\n 'year',\n 'ago',\n 'together',\n 'with',\n 'headache',\n 'left',\n 'eye',\n 'pain',\n 'tearing',\n 'and',\n 'increased',\n 'secretions',\n 'and',\n 'the',\n 'computed',\n 'tomography',\n '(CT',\n 'scan',\n 'of',\n 'the',\n 'brain',\n 'in',\n 'local',\n 'hospital',\n 'showed',\n 'a',\n 'sellar',\n 'region',\n 'lesion',\n 'Besides',\n '2',\n 'years',\n 'earlier',\n 'the',\n 'patient',\n 'underwent',\n 'resection',\n 'of',\n 'melanoma',\n 'in',\n 'the',\n 'left',\n 'heel',\n '(T2N0M0',\n 'ki67',\n '3–5',\n 'Stage',\n 'II',\n 'followed',\n 'by',\n 'resection',\n 'of',\n 'the',\n 'recurred',\n 'melanoma',\n 'nearby',\n 'the',\n 'primary',\n 'site',\n '15',\n 'months',\n 'later',\n '(T3N3M0',\n 'Stage',\n 'III',\n 'without',\n 'lymphadenectomy',\n 'She',\n 'had',\n 'no',\n 'family',\n 'history',\n 'of',\n 'melanoma',\n 'On',\n 'physical',\n 'examination',\n 'the',\n 'patient',\n 'had',\n 'bilateral',\n 'temporal',\n 'hemianopsia',\n 'the',\n 'right',\n 'finger',\n 'counting',\n 'was',\n '1',\n 'm',\n 'and',\n 'the',\n 'left',\n 'finger',\n 'counting',\n 'was',\n 'no',\n 'more',\n 'than',\n '0.5',\n 'm',\n 'Enlarged',\n 'lymph',\n 'nodes',\n 'were',\n 'palpable',\n 'in',\n 'the',\n 'right',\n 'groin',\n 'On',\n 'ophthalmologic',\n 'examination',\n 'the',\n 'patient',\n 'had',\n 'right',\n 'vision',\n 'of',\n '0.4',\n 'and',\n 'left',\n 'vision',\n 'of',\n '0.08',\n 'with',\n 'the',\n 'same',\n 'intraocular',\n 'pressure',\n '15',\n 'mm',\n 'Hg',\n 'bilaterally',\n 'The',\n 'optometry',\n 'found',\n 'the',\n 'right',\n 'eye',\n 'of',\n '+6.00DS/+0.25DC∗65°',\n 'and',\n 'the',\n 'left',\n 'eye',\n 'of',\n '+6.25DS/+0.50DC∗20°',\n 'The',\n 'patient',\n 'had',\n 'maculopathy',\n 'of',\n 'both',\n 'eyes',\n 'and',\n 'optic',\n 'atrophy',\n 'of',\n 'the',\n 'left',\n 'eye',\n 'Light',\n 'reflex',\n 'and',\n 'eye',\n 'movement',\n 'of',\n 'both',\n 'eyes',\n 'were',\n 'normal',\n 'CT',\n 'scans',\n 'of',\n 'the',\n 'brain',\n 'parenchyma',\n 'orbital',\n 'and',\n 'chest',\n 'were',\n 'unremarkable',\n 'CT',\n 'scan',\n 'and',\n 'ultrasound',\n 'examination',\n 'of',\n 'the',\n 'abdomen',\n 'showed',\n 'hepatic',\n 'portal',\n 'and',\n 'retroperitoneal',\n 'lymphadenectasis',\n 'and',\n 'enlarged',\n 'left',\n 'lobe',\n 'of',\n 'the',\n 'liver',\n 'with',\n 'substantial',\n 'placeholder',\n 'lesions',\n 'Ultrasound',\n 'examination',\n 'of',\n 'bilateral',\n 'inguinal',\n 'lymph',\n 'nodes',\n 'discovered',\n 'multiple',\n 'low',\n 'echo',\n 'light',\n 'groups',\n 'the',\n 'largest',\n 'of',\n 'which',\n 'was',\n '31',\n 'mm',\n 'in',\n 'diameter',\n 'with',\n 'hilus',\n 'of',\n 'the',\n 'echo',\n 'and',\n 'asymmetrical',\n 'thickening',\n 'of',\n 'the',\n 'skin',\n 'CT',\n 'scan',\n 'of',\n 'sellar',\n 'region',\n 'revealed',\n 'a',\n 'crumby',\n 'mass',\n 'protruding',\n 'out',\n 'of',\n 'the',\n 'sphenoid',\n 'sinus',\n 'with',\n 'obscure',\n 'boundary',\n 'and',\n 'bone',\n 'destruction',\n 'And',\n 'the',\n 'average',\n 'CT',\n 'value',\n 'of',\n 'the',\n 'mass',\n 'was',\n '46',\n 'HU',\n 'Sellar',\n 'region',\n 'magnetic',\n 'resonance',\n 'imaging',\n '(MRI',\n 'revealed',\n 'a',\n 'round',\n 'mass',\n 'of',\n '30',\n 'mm',\n 'in',\n 'diameter',\n 'in',\n 'the',\n 'enlarged',\n 'sellae',\n '(Fig.1A',\n 'B',\n 'The',\n 'mass',\n 'showed',\n 'isointense',\n 'in',\n 'T1-weighted',\n 'images',\n '(T1-WI',\n 'and',\n 'T2-weighted',\n 'images',\n '(T2-WI',\n 'with',\n 'homogeneous',\n 'enhancement',\n 'after',\n 'Gadolinium-DTPA',\n 'injection',\n 'and',\n 'dural',\n 'tail',\n 'sign',\n 'was',\n 'seen',\n 'Small',\n 'foci',\n 'inside',\n 'the',\n 'tumor',\n 'showed',\n 'hyperintense',\n 'signals',\n 'in',\n 'T1-WI',\n 'and',\n 'hypointense',\n 'signals',\n 'in',\n 'T2-WI',\n 'without',\n 'enhancement',\n 'And',\n 'it',\n 'was',\n 'seen',\n 'that',\n 'the',\n 'mass',\n 'penetrated',\n 'meninges',\n 'surrounded',\n 'the',\n 'left',\n 'internal',\n 'carotid',\n 'artery',\n 'and',\n 'was',\n 'blurred',\n 'with',\n 'the',\n 'left',\n 'optic',\n 'nerve',\n 'Pituitary',\n 'stalk',\n 'became',\n 'shorter',\n 'with',\n 'a',\n 'right',\n 'displacement',\n 'Laboratory',\n 'findings',\n 'revealed',\n 'increased',\n 'levels',\n 'of',\n 'prolactin',\n '(119.08',\n 'μg/L',\n 'normal',\n 'range',\n '5.99–30.04',\n 'μg/L',\n 'and',\n 'cortisol',\n '(677.10',\n 'nmol/L',\n 'normal',\n 'range',\n '118.60–618.00',\n 'nmol/L',\n 'and',\n 'decreased',\n 'levels',\n 'of',\n 'free',\n 'thyroxine',\n '(FT4',\n '(6.04',\n 'pmol/L',\n 'normal',\n 'range',\n '12.00–22.00',\n 'pmol/L',\n 'and',\n 'free',\n 'triiodothyronine',\n '(FT3',\n '(2.09',\n 'pmol/L',\n 'normal',\n 'range',\n '3.50–6.50',\n 'pmol/L',\n 'The',\n 'patient',\n 'was',\n 'diagnosed',\n 'with',\n 'a',\n 'giant',\n 'prolactinoma',\n 'The',\n 'patient',\n 'underwent',\n 'transnasal',\n 'transsphenoidal',\n 'surgery',\n 'to',\n 'remove',\n 'the',\n 'tumor',\n 'and',\n 'relieve',\n 'the',\n 'compression',\n 'of',\n 'the',\n 'optic',\n 'nerve',\n 'Intraoperatively',\n 'it',\n 'was',\n 'seen',\n 'that',\n 'the',\n 'tumor',\n 'invaded',\n 'and',\n 'filled',\n 'the',\n 'left',\n 'interval',\n 'of',\n 'the',\n 'sphenoid',\n 'sinus',\n 'and',\n 'part',\n 'of',\n 'bone',\n 'in',\n 'sellar',\n 'floor',\n 'and',\n 'left',\n 'side',\n 'parasellar',\n 'was',\n 'destroyed',\n 'and',\n 'absorbed',\n 'A',\n 'little',\n 'normal',\n 'pituitary',\n 'tissue',\n 'was',\n 'seen',\n 'in',\n 'the',\n 'top',\n 'right',\n 'of',\n 'tumor',\n 'in',\n 'the',\n 'sellar',\n 'turcica',\n 'The',\n 'tumor',\n 'was',\n 'reddish',\n 'black',\n 'with',\n 'extremely',\n 'rich',\n 'blood',\n 'supply',\n 'and',\n 'had',\n 'close',\n 'adhesion',\n 'to',\n 'the',\n 'surrounding',\n 'structure',\n 'The',\n 'texture',\n 'in',\n 'the',\n 'center',\n 'of',\n 'the',\n 'tumor',\n 'was',\n 'soft',\n 'and',\n 'much',\n 'tougher',\n 'over',\n 'the',\n 'rim',\n 'Intraoperative',\n 'frozen-section',\n 'examination',\n 'found',\n 'melanin',\n 'granules',\n 'and',\n 'it',\n 'was',\n 'considered',\n 'to',\n 'be',\n 'malignant',\n 'melanoma',\n 'or',\n 'meningioma',\n 'The',\n 'tumor',\n 'cells',\n 'were',\n 'composed',\n 'of',\n 'eosinophilic',\n 'staining',\n 'epithelial',\n 'cells',\n 'Most',\n 'of',\n 'cell',\n 'nuclei',\n 'were',\n 'round',\n 'a',\n 'few',\n 'were',\n 'reniform',\n 'and',\n 'hippocrepiform',\n 'with',\n 'evident',\n 'nucleoli',\n 'and',\n 'nuclear',\n 'fission',\n 'was',\n 'seen',\n 'The',\n 'tumor',\n 'showed',\n 'no',\n 'evidence',\n 'of',\n 'necrosis',\n '(Fig.2',\n 'The',\n 'tumor',\n 'was',\n 'immunopositive',\n 'focally',\n 'for',\n 'melanoma-specific',\n 'markers',\n 'such',\n 'as',\n 'S-100',\n 'HMB45',\n 'and',\n 'Vimentin',\n 'and',\n 'immunopositive',\n 'for',\n 'neuroendocrine',\n 'tumor',\n 'markers',\n 'such',\n 'as',\n 'CgA',\n 'and',\n 'Syn',\n '(Fig.3',\n 'The',\n 'Ki67',\n 'index',\n 'was',\n '3',\n 'to',\n '5',\n 'it',\n 'was',\n 'higher',\n 'in',\n 'metastatic',\n 'melanoma',\n 'than',\n 'in',\n 'the',\n 'adenomatous',\n 'component',\n 'Taken',\n 'the',\n 'melanoma',\n 'history',\n 'and',\n 'suspected',\n 'lymph',\n 'node',\n 'and',\n 'hepatic',\n 'metastasis',\n 'into',\n 'consideration',\n 'the',\n 'patient',\n 'was',\n 'diagnosised',\n 'with',\n 'MMPA',\n 'After',\n 'surgery',\n 'significant',\n 'relief',\n 'was',\n 'seen',\n 'in',\n 'visual',\n 'field',\n 'and',\n 'headache',\n 'and',\n 'the',\n 'level',\n 'of',\n 'prolactin',\n 'cortisol',\n 'and',\n 'FT4',\n 'returned',\n 'to',\n 'normal',\n 'with',\n 'hormone',\n 'replacement',\n 'therapy',\n 'Because',\n 'the',\n 'focal',\n 'liver',\n 'lesions',\n 'and',\n 'lymphadenectasis',\n 'did',\n 'not',\n 'cause',\n 'much',\n 'discomfort',\n 'the',\n 'patient',\n 'refused',\n 'any',\n 'further',\n 'surgical',\n 'intervention',\n 'or',\n 'other',\n 'treatment',\n 'She',\n 'was',\n 'discharged',\n 'from',\n 'the',\n 'hospital',\n 'immediately',\n 'and',\n 'was',\n 'disease',\n 'free',\n 'until',\n '2',\n 'months',\n 'after',\n 'the',\n 'third',\n 'surgery',\n 'The',\n 'patient',\n 'successively',\n 'found',\n 'new',\n 'melanoma',\n 'metastatic',\n 'sites',\n 'in',\n 'the',\n 'skin',\n 'of',\n 'lower',\n 'left',\n 'leg',\n 'knees',\n 'the',\n 'upper',\n 'left',\n 'leg',\n 'the',\n 'left',\n 'groin',\n 'and',\n 'the',\n 'right',\n 'groin',\n 'and',\n 'the',\n 'right',\n 'leg',\n 'At',\n 'the',\n 'follow-up',\n 'in',\n 'late',\n 'January',\n '2016',\n 'the',\n 'patient',\n 'could',\n 'not',\n 'walk',\n 'and',\n 'live',\n 'by',\n 'herself',\n 'and',\n 'was',\n 'depressed',\n 'At',\n 'the',\n 'latest',\n 'follow-up',\n 'in',\n 'late',\n 'January',\n '2017',\n 'the',\n 'patient',\n 'was',\n 'alive',\n 'with',\n 'worse',\n 'symptoms',\n 'she',\n 'had',\n 'sensory',\n 'deficits',\n 'of',\n 'both',\n 'legs',\n 'which',\n 'could',\n 'not',\n 'move',\n 'hyperalgesia',\n 'of',\n 'hands',\n 'and',\n 'mouth',\n 'impaired',\n 'intelligence',\n 'but',\n 'she',\n 'lived',\n 'well',\n 'with',\n 'the',\n 'disease',\n 'by',\n 'careful',\n 'nursing',\n 'of',\n 'her',\n 'daughter']"
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5002 5011 16 27\n",
      "5002 5011 28 33\n",
      "5002 5011 38 46\n",
      "5002 5011 94 112\n",
      "5002 5011 163 171\n",
      "5002 5011 198 204\n",
      "5002 5011 236 244\n",
      "5002 5011 287 295\n",
      "5002 5011 297 305\n",
      "5002 5011 306 310\n",
      "5002 5011 312 319\n",
      "5002 5011 334 344\n",
      "5002 5011 354 373\n",
      "5002 5011 375 377\n",
      "5002 5011 391 396\n",
      "5002 5011 424 437\n",
      "5002 5011 438 444\n",
      "5002 5011 494 503\n",
      "5002 5011 507 515\n",
      "5002 5011 523 532\n",
      "5002 5011 534 540\n",
      "5002 5011 542 551\n",
      "5002 5011 553 561\n",
      "5002 5011 576 585\n",
      "5002 5011 602 610\n",
      "5002 5011 611 634\n",
      "5002 5011 652 658\n",
      "5002 5011 660 669\n",
      "5002 5011 680 695\n",
      "5002 5011 705 734\n",
      "5002 5011 739 759\n",
      "5002 5011 796 807\n",
      "5002 5011 813 834\n",
      "5002 5011 839 842\n",
      "5002 5011 852 872\n",
      "5002 5011 877 895\n",
      "5002 5011 897 905\n",
      "5002 5011 906 917\n",
      "5002 5011 939 950\n",
      "5002 5011 955 981\n",
      "5002 5011 999 1011\n",
      "5002 5011 1015 1018\n",
      "5002 5011 1023 1034\n",
      "5002 5011 1038 1042\n",
      "5002 5011 1058 1078\n",
      "5002 5011 1079 1087\n",
      "5002 5011 1105 1114\n",
      "5002 5011 1125 1134\n",
      "5002 5011 1138 1157\n",
      "5002 5011 1166 1174\n",
      "5002 5011 1178 1197\n",
      "5002 5011 1215 1226\n",
      "5002 5011 1230 1239\n",
      "5002 5011 1244 1257\n",
      "5002 5011 1265 1273\n",
      "5002 5011 1275 1287\n",
      "5002 5011 1292 1304\n",
      "5002 5011 1308 1317\n",
      "5002 5011 1323 1329\n",
      "5002 5011 1331 1333\n",
      "5002 5011 1347 1363\n",
      "5002 5011 1365 1372\n",
      "5002 5011 1378 1383\n",
      "5002 5011 1389 1401\n",
      "5002 5011 1403 1405\n",
      "5002 5011 1415 1425\n",
      "5002 5011 1445 1452\n",
      "5002 5011 1460 1474\n",
      "5002 5011 1479 1494\n",
      "5002 5011 1495 1511\n",
      "5002 5011 1516 1524\n",
      "5002 5011 1525 1547\n",
      "5002 5011 1577 1584\n",
      "5002 5011 1586 1596\n",
      "5002 5011 1622 1642\n",
      "5002 5011 1663 1684\n",
      "5002 5011 1770 1780\n",
      "5002 5011 1788 1792\n",
      "5002 5011 1794 1796\n",
      "5002 5011 1805 1818\n",
      "5002 5011 1837 1841\n",
      "5002 5011 1865 1879\n",
      "5002 5011 1941 1949\n",
      "5002 5011 1957 1961\n",
      "5002 5011 1966 1971\n",
      "5002 5011 1973 1986\n",
      "5002 5011 1987 2013\n",
      "5002 5011 2015 2018\n",
      "5002 5011 2037 2041\n",
      "5002 5011 2070 2085\n",
      "5002 5011 2115 2125\n",
      "5002 5011 2129 2147\n",
      "5002 5011 2149 2154\n",
      "5002 5011 2160 2178\n",
      "5002 5011 2180 2185\n",
      "5002 5011 2205 2216\n",
      "5002 5011 2315 2335\n",
      "5002 5011 2339 2344\n",
      "5002 5011 2349 2368\n",
      "5002 5011 2372 2377\n",
      "5002 5011 2441 2449\n",
      "5002 5011 2466 2494\n",
      "5002 5011 2521 2537\n",
      "5002 5011 2539 2554\n",
      "5002 5011 2562 2569\n",
      "5002 5011 2597 2616\n",
      "5002 5011 2626 2635\n",
      "5002 5011 2646 2655\n",
      "5002 5011 2657 2668\n",
      "5002 5011 2704 2712\n",
      "5002 5011 2714 2727\n",
      "5002 5011 2768 2777\n",
      "5002 5011 2788 2802\n",
      "5002 5011 2804 2807\n",
      "5002 5011 2810 2821\n",
      "5002 5011 2860 2881\n",
      "5002 5011 2883 2886\n",
      "5002 5011 2889 2900\n",
      "5002 5011 2973 2985\n",
      "5002 5011 3036 3043\n",
      "5002 5011 3151 3156\n",
      "5002 5011 3180 3215\n",
      "5002 5011 3229 3249\n",
      "5002 5011 3254 3274\n",
      "5002 5011 3279 3288\n",
      "5002 5011 3293 3301\n",
      "5002 5011 3378 3392\n",
      "5002 5011 3602 3628\n",
      "5002 5011 3635 3651\n",
      "5002 5011 3681 3699\n",
      "5002 5011 3703 3713\n",
      "5002 5011 3796 3807\n",
      "5002 5011 3831 3839\n",
      "5002 5011 3844 3858\n",
      "5002 5011 3864 3871\n",
      "5002 5011 3872 3880\n",
      "5002 5011 3886 3901\n",
      "5002 5011 3906 3910\n",
      "5002 5011 3944 3952\n",
      "5002 5011 3976 3990\n",
      "5002 5011 4003 4028\n",
      "5002 5011 4037 4042\n",
      "5002 5011 4044 4049\n",
      "5002 5011 4055 4063\n",
      "5002 5011 4069 4083\n",
      "5002 5011 4088 4116\n",
      "5002 5011 4125 4128\n",
      "5002 5011 4133 4136\n",
      "5002 5011 4150 4160\n",
      "5002 5011 4165 4173\n",
      "5002 5011 4182 4188\n",
      "5002 5011 4375 4379\n",
      "5002 5011 4408 4414\n",
      "5002 5011 4427 4439\n",
      "5002 5011 4444 4452\n",
      "5002 5011 4471 4480\n",
      "5002 5011 4482 4490\n",
      "5002 5011 4496 4499\n",
      "5002 5011 4512 4518\n",
      "5002 5011 4524 4551\n",
      "5002 5011 4625 4635\n",
      "5002 5011 4669 4690\n",
      "5002 5011 4719 4729\n",
      "5002 5011 4768 4775\n",
      "5002 5011 4856 4864\n",
      "5002 5011 4865 4881\n",
      "5002 5011 4889 4911\n",
      "5002 5011 4924 4938\n",
      "5002 5011 4944 4954\n",
      "5002 5011 4963 4974\n",
      "5002 5011 4984 4993\n",
      "5002 5011 5002 5011\n",
      "5002 5011 5089 5098\n",
      "5002 5011 5114 5123\n",
      "5002 5011 5164 5169\n",
      "5002 5011 5181 5189\n",
      "5002 5011 5199 5215\n",
      "5002 5011 5219 5228\n",
      "5002 5011 5236 5250\n",
      "5002 5011 5252 5264\n",
      "5002 5011 5268 5273\n",
      "5002 5011 5278 5283\n",
      "5002 5011 5285 5306\n",
      "5002 5011 5355 5362\n",
      "5114 5123 16 27\n",
      "5114 5123 28 33\n",
      "5114 5123 38 46\n",
      "5114 5123 94 112\n",
      "5114 5123 163 171\n",
      "5114 5123 198 204\n",
      "5114 5123 236 244\n",
      "5114 5123 287 295\n",
      "5114 5123 297 305\n",
      "5114 5123 306 310\n",
      "5114 5123 312 319\n",
      "5114 5123 334 344\n",
      "5114 5123 354 373\n",
      "5114 5123 375 377\n",
      "5114 5123 391 396\n",
      "5114 5123 424 437\n",
      "5114 5123 438 444\n",
      "5114 5123 494 503\n",
      "5114 5123 507 515\n",
      "5114 5123 523 532\n",
      "5114 5123 534 540\n",
      "5114 5123 542 551\n",
      "5114 5123 553 561\n",
      "5114 5123 576 585\n",
      "5114 5123 602 610\n",
      "5114 5123 611 634\n",
      "5114 5123 652 658\n",
      "5114 5123 660 669\n",
      "5114 5123 680 695\n",
      "5114 5123 705 734\n",
      "5114 5123 739 759\n",
      "5114 5123 796 807\n",
      "5114 5123 813 834\n",
      "5114 5123 839 842\n",
      "5114 5123 852 872\n",
      "5114 5123 877 895\n",
      "5114 5123 897 905\n",
      "5114 5123 906 917\n",
      "5114 5123 939 950\n",
      "5114 5123 955 981\n",
      "5114 5123 999 1011\n",
      "5114 5123 1015 1018\n",
      "5114 5123 1023 1034\n",
      "5114 5123 1038 1042\n",
      "5114 5123 1058 1078\n",
      "5114 5123 1079 1087\n",
      "5114 5123 1105 1114\n",
      "5114 5123 1125 1134\n",
      "5114 5123 1138 1157\n",
      "5114 5123 1166 1174\n",
      "5114 5123 1178 1197\n",
      "5114 5123 1215 1226\n",
      "5114 5123 1230 1239\n",
      "5114 5123 1244 1257\n",
      "5114 5123 1265 1273\n",
      "5114 5123 1275 1287\n",
      "5114 5123 1292 1304\n",
      "5114 5123 1308 1317\n",
      "5114 5123 1323 1329\n",
      "5114 5123 1331 1333\n",
      "5114 5123 1347 1363\n",
      "5114 5123 1365 1372\n",
      "5114 5123 1378 1383\n",
      "5114 5123 1389 1401\n",
      "5114 5123 1403 1405\n",
      "5114 5123 1415 1425\n",
      "5114 5123 1445 1452\n",
      "5114 5123 1460 1474\n",
      "5114 5123 1479 1494\n",
      "5114 5123 1495 1511\n",
      "5114 5123 1516 1524\n",
      "5114 5123 1525 1547\n",
      "5114 5123 1577 1584\n",
      "5114 5123 1586 1596\n",
      "5114 5123 1622 1642\n",
      "5114 5123 1663 1684\n",
      "5114 5123 1770 1780\n",
      "5114 5123 1788 1792\n",
      "5114 5123 1794 1796\n",
      "5114 5123 1805 1818\n",
      "5114 5123 1837 1841\n",
      "5114 5123 1865 1879\n",
      "5114 5123 1941 1949\n",
      "5114 5123 1957 1961\n",
      "5114 5123 1966 1971\n",
      "5114 5123 1973 1986\n",
      "5114 5123 1987 2013\n",
      "5114 5123 2015 2018\n",
      "5114 5123 2037 2041\n",
      "5114 5123 2070 2085\n",
      "5114 5123 2115 2125\n",
      "5114 5123 2129 2147\n",
      "5114 5123 2149 2154\n",
      "5114 5123 2160 2178\n",
      "5114 5123 2180 2185\n",
      "5114 5123 2205 2216\n",
      "5114 5123 2315 2335\n",
      "5114 5123 2339 2344\n",
      "5114 5123 2349 2368\n",
      "5114 5123 2372 2377\n",
      "5114 5123 2441 2449\n",
      "5114 5123 2466 2494\n",
      "5114 5123 2521 2537\n",
      "5114 5123 2539 2554\n",
      "5114 5123 2562 2569\n",
      "5114 5123 2597 2616\n",
      "5114 5123 2626 2635\n",
      "5114 5123 2646 2655\n",
      "5114 5123 2657 2668\n",
      "5114 5123 2704 2712\n",
      "5114 5123 2714 2727\n",
      "5114 5123 2768 2777\n",
      "5114 5123 2788 2802\n",
      "5114 5123 2804 2807\n",
      "5114 5123 2810 2821\n",
      "5114 5123 2860 2881\n",
      "5114 5123 2883 2886\n",
      "5114 5123 2889 2900\n",
      "5114 5123 2973 2985\n",
      "5114 5123 3036 3043\n",
      "5114 5123 3151 3156\n",
      "5114 5123 3180 3215\n",
      "5114 5123 3229 3249\n",
      "5114 5123 3254 3274\n",
      "5114 5123 3279 3288\n",
      "5114 5123 3293 3301\n",
      "5114 5123 3378 3392\n",
      "5114 5123 3602 3628\n",
      "5114 5123 3635 3651\n",
      "5114 5123 3681 3699\n",
      "5114 5123 3703 3713\n",
      "5114 5123 3796 3807\n",
      "5114 5123 3831 3839\n",
      "5114 5123 3844 3858\n",
      "5114 5123 3864 3871\n",
      "5114 5123 3872 3880\n",
      "5114 5123 3886 3901\n",
      "5114 5123 3906 3910\n",
      "5114 5123 3944 3952\n",
      "5114 5123 3976 3990\n",
      "5114 5123 4003 4028\n",
      "5114 5123 4037 4042\n",
      "5114 5123 4044 4049\n",
      "5114 5123 4055 4063\n",
      "5114 5123 4069 4083\n",
      "5114 5123 4088 4116\n",
      "5114 5123 4125 4128\n",
      "5114 5123 4133 4136\n",
      "5114 5123 4150 4160\n",
      "5114 5123 4165 4173\n",
      "5114 5123 4182 4188\n",
      "5114 5123 4375 4379\n",
      "5114 5123 4408 4414\n",
      "5114 5123 4427 4439\n",
      "5114 5123 4444 4452\n",
      "5114 5123 4471 4480\n",
      "5114 5123 4482 4490\n",
      "5114 5123 4496 4499\n",
      "5114 5123 4512 4518\n",
      "5114 5123 4524 4551\n",
      "5114 5123 4625 4635\n",
      "5114 5123 4669 4690\n",
      "5114 5123 4719 4729\n",
      "5114 5123 4768 4775\n",
      "5114 5123 4856 4864\n",
      "5114 5123 4865 4881\n",
      "5114 5123 4889 4911\n",
      "5114 5123 4924 4938\n",
      "5114 5123 4944 4954\n",
      "5114 5123 4963 4974\n",
      "5114 5123 4984 4993\n",
      "5114 5123 5002 5011\n",
      "5114 5123 5089 5098\n",
      "5114 5123 5114 5123\n",
      "5114 5123 5164 5169\n",
      "5114 5123 5181 5189\n",
      "5114 5123 5199 5215\n",
      "5114 5123 5219 5228\n",
      "5114 5123 5236 5250\n",
      "5114 5123 5252 5264\n",
      "5114 5123 5268 5273\n",
      "5114 5123 5278 5283\n",
      "5114 5123 5285 5306\n",
      "5114 5123 5355 5362\n"
     ]
    }
   ],
   "source": [
    "start_end_range_to_token_index = {}\n",
    "# Keep track of the current position in the text\n",
    "current_pos = 0\n",
    "# Iterate over each token in the tokens list\n",
    "for i in range(len(tokens)):\n",
    "    # Calculate the starting position of the token\n",
    "    token_start = text.find(tokens[i], current_pos)\n",
    "    token_end = token_start + len(tokens[i])\n",
    "\n",
    "    # Update the current position in the text\n",
    "    current_pos = token_end\n",
    "    # Check if the current token is inside any of the entity ranges\n",
    "    for label, start, end in entity_ranges:\n",
    "        if tokens[i] == 'follow-up':\n",
    "            print(token_start, token_end, start, end)\n",
    "        if start <= token_start and end >= token_end:\n",
    "            # If the (start, end) range is not already in the dictionary, add it with an empty list\n",
    "            if (start, end) not in start_end_range_to_token_index:\n",
    "                start_end_range_to_token_index[(start, end)] = []\n",
    "            # Add the index of the token to the list corresponding to the (start, end) range in the dictionary\n",
    "            start_end_range_to_token_index[(start, end)].append(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [],
   "source": [
    "start_end_2_idx = get_start_end_range_to_token_index(tokens, entity_ranges)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [
    {
     "data": {
      "text/plain": "['O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O']"
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "outputs": [
    {
     "data": {
      "text/plain": "{(16, 27): [4],\n (28, 33): [5],\n (38, 46): [7],\n (94, 112): [15, 16],\n (163, 171): [27],\n (198, 204): [33],\n (236, 244): [40],\n (287, 295): [48],\n (297, 305): [49, 50],\n (306, 310): [51],\n (312, 319): [52],\n (334, 344): [55],\n (354, 373): [58, 59],\n (391, 396): [64],\n (424, 437): [70, 71],\n (438, 444): [72],\n (494, 503): [80],\n (507, 515): [82],\n (523, 532): [85, 86],\n (542, 551): [88, 89],\n (553, 561): [90, 91],\n (576, 585): [94],\n (602, 610): [98],\n (611, 634): [99, 100, 101, 102],\n (660, 669): [107, 108],\n (680, 695): [110],\n (705, 734): [113, 114, 115, 116, 117],\n (739, 759): [119, 120],\n (796, 807): [126],\n (813, 834): [128, 129, 130],\n (839, 842): [132, 133],\n (852, 872): [136, 137, 138],\n (877, 895): [140, 141, 142, 143, 144],\n (897, 905): [145],\n (906, 917): [146, 147],\n (939, 950): [152, 153],\n (955, 981): [155, 156],\n (999, 1011): [160, 161],\n (1015, 1018): [163],\n (1023, 1034): [165, 166],\n (1038, 1042): [168],\n (1058, 1078): [172, 173],\n (1079, 1087): [174, 175, 176],\n (1105, 1114): [179],\n (1125, 1134): [182, 183],\n (1138, 1157): [185],\n (1166, 1174): [188, 189],\n (1178, 1197): [191],\n (1215, 1226): [195],\n (1230, 1239): [197, 198],\n (1244, 1257): [200, 201],\n (1265, 1273): [204, 205],\n (1275, 1287): [206, 207],\n (1292, 1304): [209, 210],\n (1308, 1317): [212, 213],\n (1323, 1329): [215],\n (1331, 1333): [216],\n (1347, 1363): [220, 221],\n (1365, 1372): [222],\n (1378, 1383): [224],\n (1389, 1401): [226],\n (1403, 1405): [227],\n (1415, 1425): [230],\n (1445, 1452): [234],\n (1460, 1474): [236, 237],\n (1479, 1494): [239],\n (1495, 1511): [240],\n (1516, 1524): [242],\n (1525, 1547): [243, 244, 245, 246, 247],\n (1577, 1584): [251],\n (1586, 1596): [252],\n (1622, 1642): [256, 257, 258],\n (1663, 1684): [261, 262, 263, 264],\n (1770, 1780): [281],\n (1788, 1792): [284],\n (1794, 1796): [285],\n (1805, 1818): [288, 289],\n (1837, 1841): [293],\n (1865, 1879): [298, 299],\n (1941, 1949): [309, 310],\n (1957, 1961): [313],\n (1966, 1971): [315, 316],\n (1973, 1986): [317, 318],\n (1987, 2013): [319, 320, 321],\n (2037, 2041): [326],\n (2070, 2085): [334, 335],\n (2115, 2125): [341],\n (2129, 2147): [343, 344],\n (2160, 2178): [347, 348],\n (2205, 2216): [352],\n (2315, 2335): [368, 369],\n (2339, 2344): [371],\n (2349, 2368): [373, 374],\n (2372, 2377): [376],\n (2441, 2449): [387],\n (2466, 2494): [390, 391, 392, 393],\n (2521, 2537): [399, 400, 401],\n (2539, 2554): [402, 403],\n (2562, 2569): [405],\n (2597, 2616): [410, 411],\n (2626, 2635): [413],\n (2646, 2655): [416],\n (2657, 2668): [418],\n (2704, 2712): [424],\n (2714, 2727): [426],\n (2768, 2777): [432],\n (2788, 2802): [435, 436],\n (2810, 2821): [439],\n (2860, 2881): [445, 446],\n (2889, 2900): [449],\n (2973, 2985): [461],\n (3036, 3043): [467],\n (3151, 3156): [486],\n (3180, 3215): [491, 492, 493, 494, 495, 496],\n (3229, 3249): [500, 501, 502, 503],\n (3254, 3274): [505, 506, 507],\n (3279, 3288): [509],\n (3293, 3301): [511],\n (3378, 3392): [527, 528],\n (3602, 3628): [564, 565],\n (3635, 3651): [567, 568],\n (3681, 3699): [575, 576],\n (3703, 3713): [578],\n (3796, 3807): [591, 592],\n (3831, 3839): [598],\n (3844, 3858): [600],\n (3864, 3871): [602],\n (3872, 3880): [603],\n (3886, 3901): [605, 606],\n (3906, 3910): [608],\n (3944, 3952): [615],\n (3976, 3990): [620],\n (4003, 4028): [623, 624],\n (4037, 4042): [627],\n (4044, 4049): [628],\n (4055, 4063): [630],\n (4069, 4083): [632],\n (4088, 4116): [634, 635, 636],\n (4125, 4128): [639],\n (4133, 4136): [641],\n (4150, 4160): [644, 645],\n (4165, 4173): [647, 648, 649],\n (4182, 4188): [652],\n (4375, 4379): [679],\n (4408, 4414): [683],\n (4427, 4439): [687, 688],\n (4444, 4452): [690],\n (4471, 4480): [695],\n (4482, 4490): [696],\n (4496, 4499): [698],\n (4512, 4518): [701],\n (4524, 4551): [703, 704, 705],\n (4625, 4635): [717],\n (4669, 4690): [723, 724],\n (4719, 4729): [730],\n (4768, 4775): [737],\n (4856, 4864): [751],\n (4865, 4881): [752, 753],\n (4889, 4911): [756, 757, 758, 759, 760],\n (4924, 4938): [763, 764, 765],\n (4944, 4954): [767, 768],\n (4963, 4974): [771, 772],\n (4984, 4993): [775, 776],\n (5002, 5011): [779],\n (5089, 5098): [795],\n (5114, 5123): [799],\n (5164, 5169): [807],\n (5181, 5189): [810],\n (5199, 5215): [813, 814],\n (5219, 5228): [816, 817],\n (5236, 5250): [819, 820, 821],\n (5252, 5264): [822],\n (5268, 5273): [824],\n (5278, 5283): [826],\n (5285, 5306): [827, 828],\n (5355, 5362): [838]}"
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_range_to_token_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[799] 5123\n"
     ]
    }
   ],
   "source": [
    "for label, start, end in entity_ranges:\n",
    "    # Get the list of token indices corresponding to the (start, end) range\n",
    "    token_indices = start_end_2_idx.get((start, end), [])\n",
    "    # Assign the BIO tags to each token index in the range\n",
    "    for i in token_indices:\n",
    "        if i == token_indices[0]:\n",
    "            bio_tags[i] = 'B-' + label\n",
    "        else:\n",
    "            bio_tags[i] = 'I-' + label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 5002 16\n",
      "5001 5002 28\n",
      "5001 5002 38\n",
      "5001 5002 94\n",
      "5001 5002 163\n",
      "5001 5002 198\n",
      "5001 5002 236\n",
      "5001 5002 287\n",
      "5001 5002 297\n",
      "5001 5002 306\n",
      "5001 5002 312\n",
      "5001 5002 334\n",
      "5001 5002 354\n",
      "5001 5002 375\n",
      "5001 5002 391\n",
      "5001 5002 424\n",
      "5001 5002 438\n",
      "5001 5002 494\n",
      "5001 5002 507\n",
      "5001 5002 523\n",
      "5001 5002 534\n",
      "5001 5002 542\n",
      "5001 5002 553\n",
      "5001 5002 576\n",
      "5001 5002 602\n",
      "5001 5002 611\n",
      "5001 5002 652\n",
      "5001 5002 660\n",
      "5001 5002 680\n",
      "5001 5002 705\n",
      "5001 5002 739\n",
      "5001 5002 796\n",
      "5001 5002 813\n",
      "5001 5002 839\n",
      "5001 5002 852\n",
      "5001 5002 877\n",
      "5001 5002 897\n",
      "5001 5002 906\n",
      "5001 5002 939\n",
      "5001 5002 955\n",
      "5001 5002 999\n",
      "5001 5002 1015\n",
      "5001 5002 1023\n",
      "5001 5002 1038\n",
      "5001 5002 1058\n",
      "5001 5002 1079\n",
      "5001 5002 1105\n",
      "5001 5002 1125\n",
      "5001 5002 1138\n",
      "5001 5002 1166\n",
      "5001 5002 1178\n",
      "5001 5002 1215\n",
      "5001 5002 1230\n",
      "5001 5002 1244\n",
      "5001 5002 1265\n",
      "5001 5002 1275\n",
      "5001 5002 1292\n",
      "5001 5002 1308\n",
      "5001 5002 1323\n",
      "5001 5002 1331\n",
      "5001 5002 1347\n",
      "5001 5002 1365\n",
      "5001 5002 1378\n",
      "5001 5002 1389\n",
      "5001 5002 1403\n",
      "5001 5002 1415\n",
      "5001 5002 1445\n",
      "5001 5002 1460\n",
      "5001 5002 1479\n",
      "5001 5002 1495\n",
      "5001 5002 1516\n",
      "5001 5002 1525\n",
      "5001 5002 1577\n",
      "5001 5002 1586\n",
      "5001 5002 1622\n",
      "5001 5002 1663\n",
      "5001 5002 1770\n",
      "5001 5002 1788\n",
      "5001 5002 1794\n",
      "5001 5002 1805\n",
      "5001 5002 1837\n",
      "5001 5002 1865\n",
      "5001 5002 1941\n",
      "5001 5002 1957\n",
      "5001 5002 1966\n",
      "5001 5002 1973\n",
      "5001 5002 1987\n",
      "5001 5002 2015\n",
      "5001 5002 2037\n",
      "5001 5002 2070\n",
      "5001 5002 2115\n",
      "5001 5002 2129\n",
      "5001 5002 2149\n",
      "5001 5002 2160\n",
      "5001 5002 2180\n",
      "5001 5002 2205\n",
      "5001 5002 2315\n",
      "5001 5002 2339\n",
      "5001 5002 2349\n",
      "5001 5002 2372\n",
      "5001 5002 2441\n",
      "5001 5002 2466\n",
      "5001 5002 2521\n",
      "5001 5002 2539\n",
      "5001 5002 2562\n",
      "5001 5002 2597\n",
      "5001 5002 2626\n",
      "5001 5002 2646\n",
      "5001 5002 2657\n",
      "5001 5002 2704\n",
      "5001 5002 2714\n",
      "5001 5002 2768\n",
      "5001 5002 2788\n",
      "5001 5002 2804\n",
      "5001 5002 2810\n",
      "5001 5002 2860\n",
      "5001 5002 2883\n",
      "5001 5002 2889\n",
      "5001 5002 2973\n",
      "5001 5002 3036\n",
      "5001 5002 3151\n",
      "5001 5002 3180\n",
      "5001 5002 3229\n",
      "5001 5002 3254\n",
      "5001 5002 3279\n",
      "5001 5002 3293\n",
      "5001 5002 3378\n",
      "5001 5002 3602\n",
      "5001 5002 3635\n",
      "5001 5002 3681\n",
      "5001 5002 3703\n",
      "5001 5002 3796\n",
      "5001 5002 3831\n",
      "5001 5002 3844\n",
      "5001 5002 3864\n",
      "5001 5002 3872\n",
      "5001 5002 3886\n",
      "5001 5002 3906\n",
      "5001 5002 3944\n",
      "5001 5002 3976\n",
      "5001 5002 4003\n",
      "5001 5002 4037\n",
      "5001 5002 4044\n",
      "5001 5002 4055\n",
      "5001 5002 4069\n",
      "5001 5002 4088\n",
      "5001 5002 4125\n",
      "5001 5002 4133\n",
      "5001 5002 4150\n",
      "5001 5002 4165\n",
      "5001 5002 4182\n",
      "5001 5002 4375\n",
      "5001 5002 4408\n",
      "5001 5002 4427\n",
      "5001 5002 4444\n",
      "5001 5002 4471\n",
      "5001 5002 4482\n",
      "5001 5002 4496\n",
      "5001 5002 4512\n",
      "5001 5002 4524\n",
      "5001 5002 4625\n",
      "5001 5002 4669\n",
      "5001 5002 4719\n",
      "5001 5002 4768\n",
      "5001 5002 4856\n",
      "5001 5002 4865\n",
      "5001 5002 4889\n",
      "5001 5002 4924\n",
      "5001 5002 4944\n",
      "5001 5002 4963\n",
      "5001 5002 4984\n",
      "5001 5002 5002\n",
      "5001 5002 5089\n",
      "5001 5002 5114\n",
      "5001 5002 5164\n",
      "5001 5002 5181\n",
      "5001 5002 5199\n",
      "5001 5002 5219\n",
      "5001 5002 5236\n",
      "5001 5002 5252\n",
      "5001 5002 5268\n",
      "5001 5002 5278\n",
      "5001 5002 5285\n",
      "5001 5002 5355\n"
     ]
    }
   ],
   "source": [
    "for label, start, end in entity_ranges:\n",
    "    # print(label, start, end)\n",
    "    # Keep track of the current position in the text\n",
    "    current_pos = 0\n",
    "    for i in range(len(tokens)):\n",
    "        # Calculate the starting position of the token\n",
    "        token_start = text.find(tokens[i], current_pos)\n",
    "        if tokens[i] == 'follow-up':\n",
    "            print(current_pos, token_start, start)\n",
    "        token_end = token_start + len(tokens[i])\n",
    "        # Update the current position in the text\n",
    "        current_pos = token_end\n",
    "        # for start, end in ranges:\n",
    "\n",
    "        if start <= token_start and end > token_end:\n",
    "            if token_start == start:\n",
    "                bio_tags[i] = 'B-' + label\n",
    "            else:\n",
    "                bio_tags[i] = 'I-' + label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n O\n",
      "March O\n",
      "2015 O\n",
      "a O\n",
      "62-year-old B-Age\n",
      "woman B-Sex\n",
      "was O\n",
      "admitted B-Clinical_event\n",
      "to O\n",
      "our O\n",
      "hospital O\n",
      "She O\n",
      "complained O\n",
      "of O\n",
      "progressive O\n",
      "visual B-Sign_symptom\n",
      "disturbance I-Sign_symptom\n",
      "which O\n",
      "began O\n",
      "about O\n",
      "4 O\n",
      "years O\n",
      "ago O\n",
      "and O\n",
      "was O\n",
      "treated O\n",
      "as O\n",
      "cataract B-Disease_disorder\n",
      "in O\n",
      "local O\n",
      "hospital O\n",
      "but O\n",
      "no O\n",
      "relief B-Sign_symptom\n",
      "was O\n",
      "seen O\n",
      "On O\n",
      "the O\n",
      "contrary O\n",
      "the O\n",
      "symptoms B-Sign_symptom\n",
      "aggravated O\n",
      "half O\n",
      "a O\n",
      "year O\n",
      "ago O\n",
      "together O\n",
      "with O\n",
      "headache B-Sign_symptom\n",
      "left B-Biological_structure\n",
      "eye I-Biological_structure\n",
      "pain B-Sign_symptom\n",
      "tearing B-Sign_symptom\n",
      "and O\n",
      "increased O\n",
      "secretions B-Sign_symptom\n",
      "and O\n",
      "the O\n",
      "computed B-Diagnostic_procedure\n",
      "tomography I-Diagnostic_procedure\n",
      "(CT O\n",
      "scan O\n",
      "of O\n",
      "the O\n",
      "brain B-Biological_structure\n",
      "in O\n",
      "local O\n",
      "hospital O\n",
      "showed O\n",
      "a O\n",
      "sellar B-Biological_structure\n",
      "region I-Biological_structure\n",
      "lesion B-Sign_symptom\n",
      "Besides O\n",
      "2 O\n",
      "years O\n",
      "earlier O\n",
      "the O\n",
      "patient O\n",
      "underwent O\n",
      "resection B-Therapeutic_procedure\n",
      "of O\n",
      "melanoma B-Disease_disorder\n",
      "in O\n",
      "the O\n",
      "left B-Biological_structure\n",
      "heel I-Biological_structure\n",
      "(T2N0M0 O\n",
      "ki67 B-Lab_value\n",
      "3–5 I-Lab_value\n",
      "Stage B-Lab_value\n",
      "II I-Lab_value\n",
      "followed O\n",
      "by O\n",
      "resection B-Therapeutic_procedure\n",
      "of O\n",
      "the O\n",
      "recurred O\n",
      "melanoma B-Disease_disorder\n",
      "nearby B-Biological_structure\n",
      "the I-Biological_structure\n",
      "primary I-Biological_structure\n",
      "site I-Biological_structure\n",
      "15 O\n",
      "months O\n",
      "later O\n",
      "(T3N3M0 O\n",
      "Stage B-Lab_value\n",
      "III I-Lab_value\n",
      "without O\n",
      "lymphadenectomy B-Therapeutic_procedure\n",
      "She O\n",
      "had O\n",
      "no B-Family_history\n",
      "family I-Family_history\n",
      "history I-Family_history\n",
      "of I-Family_history\n",
      "melanoma I-Family_history\n",
      "On O\n",
      "physical B-Diagnostic_procedure\n",
      "examination I-Diagnostic_procedure\n",
      "the O\n",
      "patient O\n",
      "had O\n",
      "bilateral O\n",
      "temporal O\n",
      "hemianopsia B-Sign_symptom\n",
      "the O\n",
      "right B-Diagnostic_procedure\n",
      "finger I-Diagnostic_procedure\n",
      "counting I-Diagnostic_procedure\n",
      "was O\n",
      "1 B-Lab_value\n",
      "m I-Lab_value\n",
      "and O\n",
      "the O\n",
      "left B-Diagnostic_procedure\n",
      "finger I-Diagnostic_procedure\n",
      "counting I-Diagnostic_procedure\n",
      "was O\n",
      "no B-Lab_value\n",
      "more I-Lab_value\n",
      "than I-Lab_value\n",
      "0.5 I-Lab_value\n",
      "m I-Lab_value\n",
      "Enlarged B-Sign_symptom\n",
      "lymph B-Biological_structure\n",
      "nodes I-Biological_structure\n",
      "were O\n",
      "palpable O\n",
      "in O\n",
      "the O\n",
      "right B-Biological_structure\n",
      "groin I-Biological_structure\n",
      "On O\n",
      "ophthalmologic B-Diagnostic_procedure\n",
      "examination I-Diagnostic_procedure\n",
      "the O\n",
      "patient O\n",
      "had O\n",
      "right B-Diagnostic_procedure\n",
      "vision I-Diagnostic_procedure\n",
      "of O\n",
      "0.4 B-Lab_value\n",
      "and O\n",
      "left B-Diagnostic_procedure\n",
      "vision I-Diagnostic_procedure\n",
      "of O\n",
      "0.08 B-Lab_value\n",
      "with O\n",
      "the O\n",
      "same O\n",
      "intraocular B-Diagnostic_procedure\n",
      "pressure I-Diagnostic_procedure\n",
      "15 B-Lab_value\n",
      "mm I-Lab_value\n",
      "Hg I-Lab_value\n",
      "bilaterally O\n",
      "The O\n",
      "optometry B-Diagnostic_procedure\n",
      "found O\n",
      "the O\n",
      "right B-Biological_structure\n",
      "eye I-Biological_structure\n",
      "of O\n",
      "+6.00DS/+0.25DC∗65° B-Lab_value\n",
      "and O\n",
      "the O\n",
      "left B-Biological_structure\n",
      "eye I-Biological_structure\n",
      "of O\n",
      "+6.25DS/+0.50DC∗20° B-Lab_value\n",
      "The O\n",
      "patient O\n",
      "had O\n",
      "maculopathy B-Disease_disorder\n",
      "of O\n",
      "both B-Biological_structure\n",
      "eyes I-Biological_structure\n",
      "and O\n",
      "optic B-Disease_disorder\n",
      "atrophy I-Disease_disorder\n",
      "of O\n",
      "the O\n",
      "left B-Biological_structure\n",
      "eye I-Biological_structure\n",
      "Light B-Diagnostic_procedure\n",
      "reflex I-Diagnostic_procedure\n",
      "and O\n",
      "eye B-Diagnostic_procedure\n",
      "movement I-Diagnostic_procedure\n",
      "of O\n",
      "both B-Biological_structure\n",
      "eyes I-Biological_structure\n",
      "were O\n",
      "normal B-Lab_value\n",
      "CT B-Diagnostic_procedure\n",
      "scans O\n",
      "of O\n",
      "the O\n",
      "brain B-Biological_structure\n",
      "parenchyma I-Biological_structure\n",
      "orbital B-Biological_structure\n",
      "and O\n",
      "chest B-Biological_structure\n",
      "were O\n",
      "unremarkable B-Lab_value\n",
      "CT B-Diagnostic_procedure\n",
      "scan O\n",
      "and O\n",
      "ultrasound B-Diagnostic_procedure\n",
      "examination O\n",
      "of O\n",
      "the O\n",
      "abdomen B-Biological_structure\n",
      "showed O\n",
      "hepatic B-Biological_structure\n",
      "portal I-Biological_structure\n",
      "and O\n",
      "retroperitoneal B-Biological_structure\n",
      "lymphadenectasis B-Sign_symptom\n",
      "and O\n",
      "enlarged B-Sign_symptom\n",
      "left B-Biological_structure\n",
      "lobe I-Biological_structure\n",
      "of I-Biological_structure\n",
      "the I-Biological_structure\n",
      "liver I-Biological_structure\n",
      "with O\n",
      "substantial O\n",
      "placeholder O\n",
      "lesions B-Sign_symptom\n",
      "Ultrasound B-Diagnostic_procedure\n",
      "examination O\n",
      "of O\n",
      "bilateral O\n",
      "inguinal B-Biological_structure\n",
      "lymph I-Biological_structure\n",
      "nodes I-Biological_structure\n",
      "discovered O\n",
      "multiple O\n",
      "low B-Sign_symptom\n",
      "echo I-Sign_symptom\n",
      "light I-Sign_symptom\n",
      "groups I-Sign_symptom\n",
      "the O\n",
      "largest O\n",
      "of O\n",
      "which O\n",
      "was O\n",
      "31 O\n",
      "mm O\n",
      "in O\n",
      "diameter O\n",
      "with O\n",
      "hilus O\n",
      "of O\n",
      "the O\n",
      "echo O\n",
      "and O\n",
      "asymmetrical O\n",
      "thickening B-Sign_symptom\n",
      "of O\n",
      "the O\n",
      "skin B-Biological_structure\n",
      "CT B-Diagnostic_procedure\n",
      "scan O\n",
      "of O\n",
      "sellar B-Biological_structure\n",
      "region I-Biological_structure\n",
      "revealed O\n",
      "a O\n",
      "crumby O\n",
      "mass B-Sign_symptom\n",
      "protruding O\n",
      "out O\n",
      "of O\n",
      "the O\n",
      "sphenoid B-Biological_structure\n",
      "sinus I-Biological_structure\n",
      "with O\n",
      "obscure O\n",
      "boundary O\n",
      "and O\n",
      "bone O\n",
      "destruction O\n",
      "And O\n",
      "the O\n",
      "average O\n",
      "CT B-Diagnostic_procedure\n",
      "value I-Diagnostic_procedure\n",
      "of O\n",
      "the O\n",
      "mass B-Sign_symptom\n",
      "was O\n",
      "46 B-Lab_value\n",
      "HU I-Lab_value\n",
      "Sellar B-Biological_structure\n",
      "region I-Biological_structure\n",
      "magnetic B-Diagnostic_procedure\n",
      "resonance I-Diagnostic_procedure\n",
      "imaging I-Diagnostic_procedure\n",
      "(MRI O\n",
      "revealed O\n",
      "a O\n",
      "round O\n",
      "mass B-Sign_symptom\n",
      "of O\n",
      "30 O\n",
      "mm O\n",
      "in O\n",
      "diameter O\n",
      "in O\n",
      "the O\n",
      "enlarged B-Biological_structure\n",
      "sellae I-Biological_structure\n",
      "(Fig.1A O\n",
      "B O\n",
      "The O\n",
      "mass O\n",
      "showed O\n",
      "isointense B-Sign_symptom\n",
      "in O\n",
      "T1-weighted B-Diagnostic_procedure\n",
      "images I-Diagnostic_procedure\n",
      "(T1-WI O\n",
      "and O\n",
      "T2-weighted B-Diagnostic_procedure\n",
      "images I-Diagnostic_procedure\n",
      "(T2-WI O\n",
      "with O\n",
      "homogeneous O\n",
      "enhancement B-Sign_symptom\n",
      "after O\n",
      "Gadolinium-DTPA O\n",
      "injection O\n",
      "and O\n",
      "dural O\n",
      "tail O\n",
      "sign O\n",
      "was O\n",
      "seen O\n",
      "Small O\n",
      "foci O\n",
      "inside O\n",
      "the O\n",
      "tumor O\n",
      "showed O\n",
      "hyperintense B-Sign_symptom\n",
      "signals I-Sign_symptom\n",
      "in O\n",
      "T1-WI B-Diagnostic_procedure\n",
      "and O\n",
      "hypointense B-Sign_symptom\n",
      "signals I-Sign_symptom\n",
      "in O\n",
      "T2-WI B-Diagnostic_procedure\n",
      "without O\n",
      "enhancement O\n",
      "And O\n",
      "it O\n",
      "was O\n",
      "seen O\n",
      "that O\n",
      "the O\n",
      "mass O\n",
      "penetrated O\n",
      "meninges B-Biological_structure\n",
      "surrounded O\n",
      "the O\n",
      "left B-Biological_structure\n",
      "internal I-Biological_structure\n",
      "carotid I-Biological_structure\n",
      "artery I-Biological_structure\n",
      "and O\n",
      "was O\n",
      "blurred O\n",
      "with O\n",
      "the O\n",
      "left B-Biological_structure\n",
      "optic I-Biological_structure\n",
      "nerve I-Biological_structure\n",
      "Pituitary B-Biological_structure\n",
      "stalk I-Biological_structure\n",
      "became O\n",
      "shorter B-Sign_symptom\n",
      "with O\n",
      "a O\n",
      "right O\n",
      "displacement O\n",
      "Laboratory B-Diagnostic_procedure\n",
      "findings I-Diagnostic_procedure\n",
      "revealed O\n",
      "increased B-Lab_value\n",
      "levels O\n",
      "of O\n",
      "prolactin B-Diagnostic_procedure\n",
      "(119.08 O\n",
      "μg/L B-Lab_value\n",
      "normal O\n",
      "range O\n",
      "5.99–30.04 O\n",
      "μg/L O\n",
      "and O\n",
      "cortisol B-Diagnostic_procedure\n",
      "(677.10 O\n",
      "nmol/L B-Lab_value\n",
      "normal O\n",
      "range O\n",
      "118.60–618.00 O\n",
      "nmol/L O\n",
      "and O\n",
      "decreased B-Lab_value\n",
      "levels O\n",
      "of O\n",
      "free B-Diagnostic_procedure\n",
      "thyroxine I-Diagnostic_procedure\n",
      "(FT4 O\n",
      "(6.04 O\n",
      "pmol/L B-Lab_value\n",
      "normal O\n",
      "range O\n",
      "12.00–22.00 O\n",
      "pmol/L O\n",
      "and O\n",
      "free B-Diagnostic_procedure\n",
      "triiodothyronine I-Diagnostic_procedure\n",
      "(FT3 O\n",
      "(2.09 O\n",
      "pmol/L B-Lab_value\n",
      "normal O\n",
      "range O\n",
      "3.50–6.50 O\n",
      "pmol/L O\n",
      "The O\n",
      "patient O\n",
      "was O\n",
      "diagnosed O\n",
      "with O\n",
      "a O\n",
      "giant O\n",
      "prolactinoma B-Disease_disorder\n",
      "The O\n",
      "patient O\n",
      "underwent O\n",
      "transnasal O\n",
      "transsphenoidal O\n",
      "surgery B-Therapeutic_procedure\n",
      "to O\n",
      "remove O\n",
      "the O\n",
      "tumor O\n",
      "and O\n",
      "relieve O\n",
      "the O\n",
      "compression O\n",
      "of O\n",
      "the O\n",
      "optic O\n",
      "nerve O\n",
      "Intraoperatively O\n",
      "it O\n",
      "was O\n",
      "seen O\n",
      "that O\n",
      "the O\n",
      "tumor B-Sign_symptom\n",
      "invaded O\n",
      "and O\n",
      "filled O\n",
      "the O\n",
      "left B-Biological_structure\n",
      "interval I-Biological_structure\n",
      "of I-Biological_structure\n",
      "the I-Biological_structure\n",
      "sphenoid I-Biological_structure\n",
      "sinus I-Biological_structure\n",
      "and O\n",
      "part O\n",
      "of O\n",
      "bone B-Biological_structure\n",
      "in I-Biological_structure\n",
      "sellar I-Biological_structure\n",
      "floor I-Biological_structure\n",
      "and O\n",
      "left B-Biological_structure\n",
      "side I-Biological_structure\n",
      "parasellar I-Biological_structure\n",
      "was O\n",
      "destroyed B-Sign_symptom\n",
      "and O\n",
      "absorbed B-Sign_symptom\n",
      "A O\n",
      "little O\n",
      "normal O\n",
      "pituitary O\n",
      "tissue O\n",
      "was O\n",
      "seen O\n",
      "in O\n",
      "the O\n",
      "top O\n",
      "right O\n",
      "of O\n",
      "tumor O\n",
      "in O\n",
      "the O\n",
      "sellar B-Biological_structure\n",
      "turcica I-Biological_structure\n",
      "The O\n",
      "tumor O\n",
      "was O\n",
      "reddish O\n",
      "black O\n",
      "with O\n",
      "extremely O\n",
      "rich O\n",
      "blood O\n",
      "supply O\n",
      "and O\n",
      "had O\n",
      "close O\n",
      "adhesion O\n",
      "to O\n",
      "the O\n",
      "surrounding O\n",
      "structure O\n",
      "The O\n",
      "texture O\n",
      "in O\n",
      "the O\n",
      "center O\n",
      "of O\n",
      "the O\n",
      "tumor O\n",
      "was O\n",
      "soft O\n",
      "and O\n",
      "much O\n",
      "tougher O\n",
      "over O\n",
      "the O\n",
      "rim O\n",
      "Intraoperative O\n",
      "frozen-section B-Diagnostic_procedure\n",
      "examination I-Diagnostic_procedure\n",
      "found O\n",
      "melanin B-Sign_symptom\n",
      "granules I-Sign_symptom\n",
      "and O\n",
      "it O\n",
      "was O\n",
      "considered O\n",
      "to O\n",
      "be O\n",
      "malignant B-Disease_disorder\n",
      "melanoma I-Disease_disorder\n",
      "or O\n",
      "meningioma B-Disease_disorder\n",
      "The O\n",
      "tumor O\n",
      "cells O\n",
      "were O\n",
      "composed O\n",
      "of O\n",
      "eosinophilic O\n",
      "staining O\n",
      "epithelial O\n",
      "cells O\n",
      "Most O\n",
      "of O\n",
      "cell B-Diagnostic_procedure\n",
      "nuclei I-Diagnostic_procedure\n",
      "were O\n",
      "round O\n",
      "a O\n",
      "few O\n",
      "were O\n",
      "reniform B-Lab_value\n",
      "and O\n",
      "hippocrepiform B-Lab_value\n",
      "with O\n",
      "evident B-Lab_value\n",
      "nucleoli B-Diagnostic_procedure\n",
      "and O\n",
      "nuclear B-Diagnostic_procedure\n",
      "fission I-Diagnostic_procedure\n",
      "was O\n",
      "seen B-Lab_value\n",
      "The O\n",
      "tumor O\n",
      "showed O\n",
      "no O\n",
      "evidence O\n",
      "of O\n",
      "necrosis B-Sign_symptom\n",
      "(Fig.2 O\n",
      "The O\n",
      "tumor O\n",
      "was O\n",
      "immunopositive B-Lab_value\n",
      "focally O\n",
      "for O\n",
      "melanoma-specific B-Diagnostic_procedure\n",
      "markers I-Diagnostic_procedure\n",
      "such O\n",
      "as O\n",
      "S-100 B-Diagnostic_procedure\n",
      "HMB45 B-Diagnostic_procedure\n",
      "and O\n",
      "Vimentin B-Diagnostic_procedure\n",
      "and O\n",
      "immunopositive B-Lab_value\n",
      "for O\n",
      "neuroendocrine B-Diagnostic_procedure\n",
      "tumor I-Diagnostic_procedure\n",
      "markers I-Diagnostic_procedure\n",
      "such O\n",
      "as O\n",
      "CgA B-Diagnostic_procedure\n",
      "and O\n",
      "Syn B-Diagnostic_procedure\n",
      "(Fig.3 O\n",
      "The O\n",
      "Ki67 B-Diagnostic_procedure\n",
      "index I-Diagnostic_procedure\n",
      "was O\n",
      "3 B-Lab_value\n",
      "to I-Lab_value\n",
      "5 I-Lab_value\n",
      "it O\n",
      "was O\n",
      "higher B-Lab_value\n",
      "in O\n",
      "metastatic O\n",
      "melanoma O\n",
      "than O\n",
      "in O\n",
      "the O\n",
      "adenomatous O\n",
      "component O\n",
      "Taken O\n",
      "the O\n",
      "melanoma O\n",
      "history O\n",
      "and O\n",
      "suspected O\n",
      "lymph O\n",
      "node O\n",
      "and O\n",
      "hepatic O\n",
      "metastasis O\n",
      "into O\n",
      "consideration O\n",
      "the O\n",
      "patient O\n",
      "was O\n",
      "diagnosised O\n",
      "with O\n",
      "MMPA B-Disease_disorder\n",
      "After O\n",
      "surgery O\n",
      "significant O\n",
      "relief B-Lab_value\n",
      "was O\n",
      "seen O\n",
      "in O\n",
      "visual B-Diagnostic_procedure\n",
      "field I-Diagnostic_procedure\n",
      "and O\n",
      "headache B-Sign_symptom\n",
      "and O\n",
      "the O\n",
      "level O\n",
      "of O\n",
      "prolactin B-Diagnostic_procedure\n",
      "cortisol B-Diagnostic_procedure\n",
      "and O\n",
      "FT4 B-Diagnostic_procedure\n",
      "returned O\n",
      "to O\n",
      "normal B-Lab_value\n",
      "with O\n",
      "hormone B-Medication\n",
      "replacement I-Medication\n",
      "therapy I-Medication\n",
      "Because O\n",
      "the O\n",
      "focal O\n",
      "liver O\n",
      "lesions O\n",
      "and O\n",
      "lymphadenectasis O\n",
      "did O\n",
      "not O\n",
      "cause O\n",
      "much O\n",
      "discomfort B-Sign_symptom\n",
      "the O\n",
      "patient O\n",
      "refused O\n",
      "any O\n",
      "further O\n",
      "surgical B-Therapeutic_procedure\n",
      "intervention I-Therapeutic_procedure\n",
      "or O\n",
      "other O\n",
      "treatment O\n",
      "She O\n",
      "was O\n",
      "discharged B-Clinical_event\n",
      "from O\n",
      "the O\n",
      "hospital O\n",
      "immediately O\n",
      "and O\n",
      "was O\n",
      "disease B-Disease_disorder\n",
      "free O\n",
      "until O\n",
      "2 O\n",
      "months O\n",
      "after O\n",
      "the O\n",
      "third O\n",
      "surgery O\n",
      "The O\n",
      "patient O\n",
      "successively O\n",
      "found O\n",
      "new O\n",
      "melanoma B-Disease_disorder\n",
      "metastatic B-Sign_symptom\n",
      "sites I-Sign_symptom\n",
      "in O\n",
      "the O\n",
      "skin B-Biological_structure\n",
      "of I-Biological_structure\n",
      "lower I-Biological_structure\n",
      "left I-Biological_structure\n",
      "leg I-Biological_structure\n",
      "knees O\n",
      "the O\n",
      "upper B-Biological_structure\n",
      "left I-Biological_structure\n",
      "leg I-Biological_structure\n",
      "the O\n",
      "left B-Biological_structure\n",
      "groin I-Biological_structure\n",
      "and O\n",
      "the O\n",
      "right B-Biological_structure\n",
      "groin I-Biological_structure\n",
      "and O\n",
      "the O\n",
      "right B-Biological_structure\n",
      "leg I-Biological_structure\n",
      "At O\n",
      "the O\n",
      "follow-up B-Clinical_event\n",
      "in O\n",
      "late O\n",
      "January O\n",
      "2016 O\n",
      "the O\n",
      "patient O\n",
      "could O\n",
      "not O\n",
      "walk O\n",
      "and O\n",
      "live O\n",
      "by O\n",
      "herself O\n",
      "and O\n",
      "was O\n",
      "depressed B-Disease_disorder\n",
      "At O\n",
      "the O\n",
      "latest O\n",
      "follow-up B-Clinical_event\n",
      "in O\n",
      "late O\n",
      "January O\n",
      "2017 O\n",
      "the O\n",
      "patient O\n",
      "was O\n",
      "alive B-Sign_symptom\n",
      "with O\n",
      "worse O\n",
      "symptoms B-Sign_symptom\n",
      "she O\n",
      "had O\n",
      "sensory B-Sign_symptom\n",
      "deficits I-Sign_symptom\n",
      "of O\n",
      "both B-Biological_structure\n",
      "legs I-Biological_structure\n",
      "which O\n",
      "could B-Sign_symptom\n",
      "not I-Sign_symptom\n",
      "move I-Sign_symptom\n",
      "hyperalgesia B-Sign_symptom\n",
      "of O\n",
      "hands B-Biological_structure\n",
      "and O\n",
      "mouth B-Biological_structure\n",
      "impaired B-Sign_symptom\n",
      "intelligence I-Sign_symptom\n",
      "but O\n",
      "she O\n",
      "lived O\n",
      "well O\n",
      "with O\n",
      "the O\n",
      "disease O\n",
      "by O\n",
      "careful O\n",
      "nursing B-Clinical_event\n",
      "of O\n",
      "her O\n",
      "daughter O\n"
     ]
    }
   ],
   "source": [
    "for token, tag in zip(tokens, bio_tags):\n",
    "    print(token, tag)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [
    {
     "data": {
      "text/plain": "'follow-up'"
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
